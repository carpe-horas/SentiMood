{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 & 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key 로드 성공!\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리 불러오기\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드 (OpenAI API Key 불러오기)\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"✅ OpenAI API Key 로드 성공!\")\n",
    "else:\n",
    "    print(\"⚠️ OpenAI API Key가 없습니다. .env 파일을 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 말투 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 말투 데이터셋 로드\n",
    "style_data_path = \"../../data/tone_dataset.csv\"  # 말투 데이터셋 파일 경로\n",
    "df = pd.read_csv(style_data_path)\n",
    "\n",
    "# ✅ 랜덤하게 5개의 예제 선택\n",
    "style_examples = \"\\n\".join([\n",
    "    f\"- 원본: {row['original']}\\n  - 변환: {row['converted']}\" \n",
    "    for _, row in df.sample(5).iterrows()\n",
    "])\n",
    "\n",
    "print(\"✅ 말투 데이터셋 로드 완료!\")\n",
    "print(style_examples)  # 로드된 데이터 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 프롬프트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ LangChain ChatPromptTemplate 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"당신은 청소년 고민 상담을 도와주는 AI 챗봇입니다.  \n",
    "사용자가 편안하게 대화를 나눌 수 있도록, 친구처럼 자연스럽게 말해 주세요.  \n",
    "응답을 생성할 때, 아래 스타일 예제를 참고해서 대화 스타일을 유지하세요.\n",
    "\n",
    "💡 **말투 스타일 예제 (Few-shot 데이터셋 기반)**:  \n",
    "{style_examples}\n",
    "\n",
    "📌 **사용자 입력**:  \n",
    "\"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "])\n",
    "\n",
    "print(\"✅ LangChain 프롬프트 설정 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터DB 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG 설정 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_10124\\1012020170.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n"
     ]
    }
   ],
   "source": [
    "# ✅ 벡터 DB 로드\n",
    "vectorstore = FAISS.load_local('../../data/db/faiss', OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "# ✅ 대화 기반 검색을 위한 Retriever 설정\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ✅ Memory 설정 (대화 이력 저장)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "\n",
    "# ✅ Conversational RAG 설정\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "conversation_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}  # 프롬프트 반영\n",
    ")\n",
    "\n",
    "print(\"✅ Conversational RAG 설정 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 검색 & 대화 흐름 최적화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_rag_response(user_input):\n",
    "    \"\"\"RAG 검색 실행 후, 결과가 적절한지 판단\"\"\"\n",
    "    response = conversation_rag.invoke({\"question\": user_input})\n",
    "    answer = response[\"answer\"]\n",
    "\n",
    "    # ✅ 검색 결과가 의미 있는 경우만 반환\n",
    "    if len(answer) > 5:  # 의미 있는 답변인지 간단히 체크 (길이 기준)\n",
    "        return answer\n",
    "    else:\n",
    "        return None  # 의미 없는 경우 RAG 결과 사용 안 함\n",
    "\n",
    "print(\"✅ RAG 검색 함수 설정 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗봇 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot():\n",
    "    while True:\n",
    "        user_input = input(\"\\n당신: \")\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\n대화를 종료합니다. 다음에 또 만나요.\\n\")\n",
    "            break\n",
    "\n",
    "        # ✅ 항상 RAG 실행\n",
    "        rag_response = get_relevant_rag_response(user_input)\n",
    "\n",
    "        # ✅ 최종 프롬프트에 데이터 적용\n",
    "        final_prompt = prompt.format(\n",
    "            style_examples=style_examples,  # 말투 데이터셋 반영\n",
    "            user_input=user_input\n",
    "        )\n",
    "\n",
    "        # ✅ LLM 호출 (RAG 응답이 있으면 포함)\n",
    "        if rag_response:\n",
    "            final_prompt += f\"\\n📂 참고할 상담 사례:\\n{rag_response}\"\n",
    "\n",
    "        # ✅ LLM이 최종 응답 생성\n",
    "        final_answer = llm.invoke(final_prompt)\n",
    "\n",
    "        print(\"\\n챗봇:\\n\", final_answer)\n",
    "\n",
    "print(\"✅ 챗봇 실행 준비 완료! 'chat_with_bot()' 실행하면 대화 시작!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 고민 상담 챗봇 시작! (종료는는 'exit' 입력)\n",
      "👤 사용자: 나 너무 힘들어\n",
      "\n",
      "📂 RAG 검색된 문서를 기반으로 답변 중...\n",
      "🤖 챗봇: \"음, 요즘 많이 힘든 것 같구나. 다른 사람들은 잘 지내는 것 같은데, 너만 힘든 기분이 드는 건 정말 속상할 것 같아. 그럴 때는 정말 외롭고 힘들겠지. 최근에 어떤 일이 있어서 그렇게 느끼게 되었어?\"\n",
      "👤 사용자: 애들이 나만 빼고 밥 먹으러 가.\n",
      "\n",
      "📂 RAG 검색된 문서를 기반으로 답변 중...\n",
      "🤖 챗봇: \"아, 그런 일이 있었구나. 친구들이 나만 빼고 밥 먹으러 가면 정말 속상하고 혼자 남겨진 기분이 들겠어. 나만 소외된 것 같아서 기분이 많이 무거워질 것 같아. 혹시 최근에 친구들과의 관계에서 어떤 변화가 있었던 것 같아? 아니면 어떤 일로 인해 그런 기분이 들었는지 이야기해 줄 수 있어?\"\n",
      "👤 사용자: 그냥 날 질투하나봐\n",
      "\n",
      "📂 RAG 검색된 문서를 기반으로 답변 중...\n",
      "🤖 챗봇: \"그런 기분이 드는구나.. 누군가가 질투하는 것 같아서 마음이 불편할 것 같아. 그런 상황은 정말 힘들지. 그 친구와의 관계는 어떤지 궁금해. 혹시 어떤 행동들이 그런 생각을 하게 만들었는지 이야기해줄 수 있어?\"\n",
      "👤 사용자: exit\n",
      "🔚 상담 챗봇 종료!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"💬 고민 상담 챗봇 시작! (종료는 'exit' 입력)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"👤 사용자: \")  # 사용자 입력 받기\n",
    "    print(\"👤 사용자:\", user_input)  # 사용자 입력 즉시 출력\n",
    "    sys.stdout.flush()  # 버퍼 강제 플러시\n",
    "\n",
    "    if user_input.lower() == \"exit\":  # 'exit' 입력 시 종료\n",
    "        print(\"🔚 상담 챗봇 종료!\")\n",
    "        break\n",
    "\n",
    "    # ✅ 메모리에 저장된 대화 기록 로드\n",
    "    chat_history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "    # ✅ RAG 기반 응답 (자동으로 대화 기록 포함)\n",
    "    response = conversation_rag.invoke({\"question\": user_input})\n",
    "\n",
    "    # ✅ 🔍 RAG 작동 여부 확인\n",
    "    if response[\"source_documents\"]:  # 검색된 문서가 있을 경우\n",
    "        print(\"\\n📂 RAG 검색된 문서를 기반으로 답변 중...\")\n",
    "    else:  # 검색된 문서가 없을 경우\n",
    "        print(\"\\n⚠️ 벡터DB에 검색된 문서 없음. GPT 모델이 직접 답변을 생성합니다.\")\n",
    "\n",
    "    # ✅ 챗봇 응답 출력\n",
    "    print(\"🤖 챗봇:\", response[\"answer\"])\n",
    "    sys.stdout.flush()  # 챗봇 출력 후에도 플러시\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotpet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
