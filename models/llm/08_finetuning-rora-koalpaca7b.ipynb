{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: False\n",
      "현재 사용 중인 디바이스: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 현재 GPU 사용 여부 확인\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"현재 사용 중인 디바이스:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\"  # TensorFlow 강제 비활성화\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅 페이스 cli 설치 및 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de840eb66a445568178e27a672b34d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (4.48.3)\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers peft datasets tqdm accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 허깅페이스에서 모델을 다운로드하고 로컬에 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- beomi/KoAlpaca-llama-1-7b\n",
    "    - https://github.com/Beomi/KoAlpaca?tab=readme-ov-file\n",
    "    - https://huggingface.co/beomi/KoAlpaca-llama-1-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blobfile\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from blobfile) (2.3.0)\n",
      "Collecting lxml>=4.9 (from blobfile)\n",
      "  Downloading lxml-5.3.1-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock>=3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from blobfile) (3.17.0)\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 23.5 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.1-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.8/3.8 MB 45.4 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, pycryptodomex, lxml, blobfile\n",
      "Successfully installed blobfile-3.0.0 lxml-5.3.1 pycryptodomex-3.21.0 sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install blobfile sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, LlamaTokenizer  # AutoTokenizer 대신 LlamaTokenizer 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 다운로드 시도 1/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee9c50a1bac460d8da1584561a9514c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 모델 다운로드 및 저장 실행\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mload_model_with_retry\u001b[1;34m(model_name, max_retries)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 다운로드 시도 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 모델 및 토크나이저 다운로드\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# LlamaTokenizer를 명시적으로 사용 & use_fast=False 옵션 추가\u001b[39;00m\n\u001b[0;32m     20\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\modeling_utils.py:4277\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mcan_generate() \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4276\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4277\u001b[0m         model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m GenerationConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   4278\u001b[0m             pretrained_model_name_or_path,\n\u001b[0;32m   4279\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   4280\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   4281\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m   4282\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   4283\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   4284\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   4285\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   4286\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m   4287\u001b[0m             _from_auto\u001b[38;5;241m=\u001b[39mfrom_auto_class,\n\u001b[0;32m   4288\u001b[0m             _from_pipeline\u001b[38;5;241m=\u001b[39mfrom_pipeline,\n\u001b[0;32m   4289\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4290\u001b[0m         )\n\u001b[0;32m   4291\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   4292\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   4293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration config file not found, using a generation config created from the model config.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4294\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:1055\u001b[0m, in \u001b[0;36mGenerationConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name, config_file_name, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[0;32m   1052\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m config_file_name\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m-> 1055\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:923\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1291\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    279\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    280\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    281\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    302\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:93\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 다운로드 시간 제한을 환경 변수로 설정 (10분)\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"600\"\n",
    "\n",
    "# 모델명 지정 (Hugging Face에서 다운로드)\n",
    "model_name = \"beomi/KoAlpaca-llama-1-7b\"\n",
    "\n",
    "# 모델 저장 경로\n",
    "save_path = \"../../data/models/KoAlpaca-llama-1-7b\"\n",
    "\n",
    "# 모델 다운로드 (재시도 기능 추가)\n",
    "def load_model_with_retry(model_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"모델 다운로드 시도 {attempt + 1}/{max_retries}...\")\n",
    "\n",
    "            # 모델 및 토크나이저 다운로드\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "            # LlamaTokenizer를 명시적으로 사용 & use_fast=False 옵션 추가\n",
    "            tokenizer = LlamaTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "            # 패딩 토큰 설정 (LLaMA 모델은 기본적으로 pad_token이 없음)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "            # 모델 & 토크나이저 로컬 저장\n",
    "            model.save_pretrained(save_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "\n",
    "            print(f\"모델이 '{save_path}' 경로에 성공적으로 저장되었습니다!\")\n",
    "            return model, tokenizer  # 성공 시 반환\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(\"다시 시도 중...\")\n",
    "            else:\n",
    "                print(\"모델 다운로드 실패. 인터넷 연결 확인 또는 수동 다운로드 필요.\")\n",
    "                raise e\n",
    "\n",
    "# 모델 다운로드 및 저장 실행\n",
    "model, tokenizer = load_model_with_retry(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬에서 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3bd5ceea9e458a858368d142dfe0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬에서 모델을 성공적으로 불러왔습니다!\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 경로\n",
    "model_path = \"../../data/models/KoAlpaca-llama-1-7b\"\n",
    "\n",
    "# 로컬에서 모델 불러오기 (CPU 실행)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=None)\n",
    "\n",
    "# LlamaTokenizer를 사용해야 함\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path, use_fast=False)\n",
    "\n",
    "print(\"로컬에서 모델을 성공적으로 불러왔습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 10563\n",
      "Test 데이터 개수: 2641\n",
      "샘플 데이터: {'input': '저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.', 'output': '사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다. 이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다. 이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.', 'input_length': 362, 'output_length': 1015}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# CSV 파일 경로\n",
    "data_path = \"../../data/total_kor_counsel_bot_clean.csv\"\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_path)\n",
    "\n",
    "# 데이터 80:20으로 나누기 (train 80%, test 20%)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(\"Train 데이터 개수:\", len(dataset[\"train\"]))\n",
    "print(\"Test 데이터 개수:\", len(dataset[\"test\"]))\n",
    "\n",
    "# 데이터 샘플 확인 (첫 번째 데이터 출력)\n",
    "print(\"샘플 데이터:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이징 완료!\n",
      "{'input': '저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.', 'output': '사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다. 이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다. 이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.', 'input_length': 362, 'output_length': 1015, 'input_ids': [2, 29871, 239, 170, 139, 31406, 29901, 29871, 239, 163, 131, 31081, 29871, 30811, 237, 187, 139, 237, 188, 143, 30811, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 31093, 29871, 238, 170, 145, 31354, 29871, 237, 180, 187, 29871, 31378, 240, 154, 155, 30944, 31747, 31093, 29871, 238, 141, 147, 238, 133, 131, 29871, 237, 181, 134, 30393, 29871, 239, 161, 139, 31129, 31093, 29892, 29871, 31137, 31582, 31286, 29871, 31435, 31199, 239, 152, 155, 239, 141, 184, 31063, 30709, 29889, 29871, 239, 163, 131, 31081, 29871, 30393, 31306, 29871, 31953, 30791, 31054, 31093, 29871, 30890, 30826, 237, 188, 143, 30811, 29871, 239, 179, 144, 31137, 29871, 239, 161, 139, 31081, 238, 144, 179, 29892, 29871, 30890, 30826, 31054, 237, 181, 143, 29871, 30903, 31747, 31093, 31279, 31856, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 237, 191, 139, 239, 141, 184, 31063, 30709, 29889, 29871, 31306, 30903, 29871, 31345, 238, 179, 179, 31054, 237, 181, 143, 29871, 31170, 30944, 31081, 29871, 30708, 237, 181, 175, 30393, 31207, 29871, 31129, 238, 153, 167, 29871, 237, 181, 134, 31054, 29871, 30890, 31435, 31093, 31081, 29871, 31962, 238, 148, 147, 29871, 31716, 30889, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 31137, 29892, 29871, 238, 185, 139, 240, 152, 135, 31527, 30877, 29871, 240, 151, 191, 31493, 31989, 31286, 29871, 30981, 30889, 31747, 31093, 29871, 237, 183, 159, 240, 161, 139, 29871, 238, 185, 139, 240, 145, 187, 30877, 29871, 30827, 238, 185, 135, 31136, 29871, 31804, 31137, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 240, 161, 155, 238, 150, 163, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 31435, 31199, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 30393, 29871, 238, 147, 155, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30944, 30811, 31826, 29871, 30393, 238, 162, 179, 29871, 31129, 238, 163, 167, 239, 158, 131, 29871, 238, 152, 143, 31406, 31054, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 31517, 29871, 31435, 237, 181, 179, 240, 152, 163, 29871, 30970, 29871, 239, 161, 139, 31081, 29871, 31945, 238, 181, 152, 31286, 29871, 239, 152, 143, 31137, 29871, 239, 142, 185, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 142, 184, 238, 182, 131, 29901, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 30890, 30826, 30906, 29871, 31536, 237, 187, 140, 30944, 31747, 31093, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31137, 29871, 237, 182, 135, 30889, 238, 135, 167, 31527, 29889, 29871, 31345, 238, 179, 179, 31804, 30393, 29871, 30791, 31327, 238, 142, 155, 30708, 29871, 30708, 237, 181, 175, 31286, 29871, 31716, 30889, 30944, 238, 172, 179, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30877, 30709, 31081, 29871, 237, 181, 134, 31054, 31093, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 31158, 239, 181, 155, 31517, 29871, 238, 179, 158, 31137, 29871, 239, 161, 139, 30709, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 144, 151, 31231, 31207, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31804, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 30944, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 31286, 29871, 238, 179, 158, 30827, 29871, 31129, 238, 163, 184, 30709, 31081, 29871, 237, 181, 134, 239, 161, 136, 31063, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 30709, 31137, 29871, 31980, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31129, 238, 153, 167, 29871, 31137, 31582, 31286, 29871, 30944, 31137, 29871, 237, 182, 135, 31262, 29871, 237, 180, 183, 30811, 29871, 240, 152, 171, 237, 190, 155, 29871, 239, 152, 143, 30860, 31199, 31136, 238, 164, 160, 29871, 31980, 30889, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30890, 30918, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31262, 29871, 237, 181, 134, 31354], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2, 29871, 239, 170, 139, 31406, 29901, 29871, 239, 163, 131, 31081, 29871, 30811, 237, 187, 139, 237, 188, 143, 30811, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 31093, 29871, 238, 170, 145, 31354, 29871, 237, 180, 187, 29871, 31378, 240, 154, 155, 30944, 31747, 31093, 29871, 238, 141, 147, 238, 133, 131, 29871, 237, 181, 134, 30393, 29871, 239, 161, 139, 31129, 31093, 29892, 29871, 31137, 31582, 31286, 29871, 31435, 31199, 239, 152, 155, 239, 141, 184, 31063, 30709, 29889, 29871, 239, 163, 131, 31081, 29871, 30393, 31306, 29871, 31953, 30791, 31054, 31093, 29871, 30890, 30826, 237, 188, 143, 30811, 29871, 239, 179, 144, 31137, 29871, 239, 161, 139, 31081, 238, 144, 179, 29892, 29871, 30890, 30826, 31054, 237, 181, 143, 29871, 30903, 31747, 31093, 31279, 31856, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 237, 191, 139, 239, 141, 184, 31063, 30709, 29889, 29871, 31306, 30903, 29871, 31345, 238, 179, 179, 31054, 237, 181, 143, 29871, 31170, 30944, 31081, 29871, 30708, 237, 181, 175, 30393, 31207, 29871, 31129, 238, 153, 167, 29871, 237, 181, 134, 31054, 29871, 30890, 31435, 31093, 31081, 29871, 31962, 238, 148, 147, 29871, 31716, 30889, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 31137, 29892, 29871, 238, 185, 139, 240, 152, 135, 31527, 30877, 29871, 240, 151, 191, 31493, 31989, 31286, 29871, 30981, 30889, 31747, 31093, 29871, 237, 183, 159, 240, 161, 139, 29871, 238, 185, 139, 240, 145, 187, 30877, 29871, 30827, 238, 185, 135, 31136, 29871, 31804, 31137, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 240, 161, 155, 238, 150, 163, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 31435, 31199, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 30393, 29871, 238, 147, 155, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30944, 30811, 31826, 29871, 30393, 238, 162, 179, 29871, 31129, 238, 163, 167, 239, 158, 131, 29871, 238, 152, 143, 31406, 31054, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 31517, 29871, 31435, 237, 181, 179, 240, 152, 163, 29871, 30970, 29871, 239, 161, 139, 31081, 29871, 31945, 238, 181, 152, 31286, 29871, 239, 152, 143, 31137, 29871, 239, 142, 185, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 142, 184, 238, 182, 131, 29901, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 30890, 30826, 30906, 29871, 31536, 237, 187, 140, 30944, 31747, 31093, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31137, 29871, 237, 182, 135, 30889, 238, 135, 167, 31527, 29889, 29871, 31345, 238, 179, 179, 31804, 30393, 29871, 30791, 31327, 238, 142, 155, 30708, 29871, 30708, 237, 181, 175, 31286, 29871, 31716, 30889, 30944, 238, 172, 179, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30877, 30709, 31081, 29871, 237, 181, 134, 31054, 31093, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 31158, 239, 181, 155, 31517, 29871, 238, 179, 158, 31137, 29871, 239, 161, 139, 30709, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 144, 151, 31231, 31207, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31804, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 30944, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 31286, 29871, 238, 179, 158, 30827, 29871, 31129, 238, 163, 184, 30709, 31081, 29871, 237, 181, 134, 239, 161, 136, 31063, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 30709, 31137, 29871, 31980, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31129, 238, 153, 167, 29871, 31137, 31582, 31286, 29871, 30944, 31137, 29871, 237, 182, 135, 31262, 29871, 237, 180, 183, 30811, 29871, 240, 152, 171, 237, 190, 155, 29871, 239, 152, 143, 30860, 31199, 31136, 238, 164, 160, 29871, 31980, 30889, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30890, 30918, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31262, 29871, 237, 181, 134, 31354]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "# 로컬에 저장된 모델 & 토크나이저 경로\n",
    "model_path = \"../../data/models/KoAlpaca-llama-1-7b\"\n",
    "\n",
    "# LlamaTokenizer 로드\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path, use_fast=False, legacy=False)\n",
    "\n",
    "# 토크나이징 함수 정의\n",
    "def tokenize_function(examples):\n",
    "    # 리스트 형태의 데이터를 개별 문자열로 변환\n",
    "    texts = [\"질문: \" + q + \" 답변: \" + a for q, a in zip(examples[\"input\"], examples[\"output\"])]\n",
    "\n",
    "    # 토크나이징 (최대 길이 1024로 설정)\n",
    "    tokenized = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "    # labels 추가 (input_ids와 동일)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# 데이터셋 토크나이징 적용\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 토크나이징된 데이터 확인\n",
    "print(\"토크나이징 완료!\")\n",
    "print(tokenized_datasets[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 청소년 상담 특화 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 적용 완료!\n",
      "{'input_length': 362, 'output_length': 1015, 'input_ids': [2, 29871, 238, 135, 139, 31081, 29871, 239, 181, 176, 31189, 31571, 31804, 30708, 29871, 31137, 31582, 31286, 29871, 31804, 31129, 30981, 31137, 29871, 31334, 237, 179, 147, 31435, 29871, 30981, 31081, 319, 29902, 29871, 239, 188, 159, 31231, 239, 152, 191, 29889, 29871, 30791, 31737, 31013, 29871, 237, 179, 147, 30852, 30393, 29871, 30827, 239, 132, 155, 237, 180, 179, 31207, 29871, 240, 153, 140, 238, 182, 184, 239, 152, 163, 31199, 30393, 31747, 29871, 239, 163, 132, 239, 163, 139, 30944, 237, 181, 143, 29871, 30393, 31962, 30811, 31207, 29871, 30393, 31962, 240, 142, 179, 239, 192, 155, 31136, 29871, 238, 135, 166, 31129, 29871, 239, 167, 155, 29889, 238, 135, 139, 30708, 29871, 31987, 240, 152, 163, 31354, 29871, 30791, 31737, 31013, 30903, 29871, 240, 145, 187, 30944, 237, 181, 143, 29871, 31137, 31582, 31286, 29871, 240, 135, 187, 31129, 238, 137, 150, 31286, 29871, 30970, 29871, 239, 161, 139, 31136, 238, 164, 160, 29871, 31136, 239, 156, 131, 30981, 31137, 29892, 29871, 31334, 237, 179, 147, 30944, 238, 172, 179, 29871, 30890, 31225, 31517, 29871, 31013, 31285, 30784, 238, 162, 192, 237, 181, 143, 29871, 30393, 31129, 30903, 31081, 29871, 237, 180, 179, 239, 152, 191, 29889, 29871, 240, 152, 176, 31158, 29871, 239, 188, 159, 237, 186, 191, 30944, 31137, 29871, 238, 151, 179, 238, 159, 190, 30877, 29871, 238, 170, 147, 240, 139, 175, 31517, 29871, 30791, 31737, 31435, 239, 152, 191, 29871, 31435, 29889, 29871, 30944, 30811, 31826, 29892, 29871, 30791, 239, 142, 167, 30393, 29871, 30860, 238, 142, 143, 29871, 30393, 239, 152, 191, 30827, 31517, 29871, 31826, 31804, 237, 180, 179, 31207, 29871, 31774, 31527, 30944, 31747, 29871, 31734, 29871, 238, 146, 191, 29889, 29871, 239, 170, 132, 239, 163, 148, 239, 163, 132, 30918, 29871, 31435, 237, 181, 179, 239, 180, 136, 31286, 29871, 31774, 31527, 30944, 30811, 29871, 238, 170, 147, 31137, 29892, 29871, 30791, 31737, 31013, 30903, 29871, 30784, 30784, 30906, 29871, 238, 142, 184, 31286, 29871, 239, 179, 193, 31286, 29871, 30970, 29871, 239, 161, 139, 31136, 238, 164, 160, 29871, 31136, 239, 156, 131, 239, 167, 155, 29889, 13, 13, 1068, 243, 162, 149, 164, 29871, 30890, 31225, 29871, 31198, 239, 188, 156, 1068, 13, 29899, 29871, 238, 171, 191, 239, 163, 131, 29871, 30791, 31737, 31013, 30708, 29871, 237, 179, 147, 30852, 31286, 29871, 30918, 30852, 30944, 31137, 29892, 29871, 238, 151, 179, 238, 159, 190, 30877, 29871, 238, 170, 147, 30906, 29871, 31334, 237, 179, 147, 31435, 29871, 239, 167, 155, 29889, 13, 29899, 29871, 31279, 30852, 239, 163, 132, 30918, 29871, 240, 148, 159, 31680, 31286, 29871, 30791, 31737, 30944, 30811, 29871, 238, 170, 147, 31137, 29892, 29871, 237, 187, 144, 30852, 239, 163, 132, 30393, 31137, 29871, 240, 145, 187, 31734, 30877, 29871, 238, 185, 135, 31724, 30827, 31517, 29871, 31533, 30811, 31435, 29889, 13, 29899, 29871, 30791, 31737, 31013, 30903, 29871, 30890, 31225, 31517, 29871, 237, 182, 135, 239, 137, 144, 29871, 30393, 31129, 237, 179, 139, 29871, 30970, 29871, 239, 161, 139, 31136, 238, 164, 160, 29871, 239, 185, 151, 30903, 29871, 239, 170, 139, 31406, 31286, 29871, 238, 144, 155, 239, 163, 187, 29889, 13, 29899, 29871, 30791, 31737, 31013, 30903, 29871, 238, 170, 147, 30877, 29871, 31940, 31737, 31286, 29871, 239, 156, 159, 237, 182, 164, 30944, 30811, 29871, 238, 170, 147, 31137, 29892, 29871, 30791, 239, 142, 167, 31054, 29871, 30827, 238, 179, 155, 31435, 31093, 31826, 29871, 238, 142, 184, 238, 182, 131, 31435, 29889, 13, 29899, 29871, 31129, 238, 163, 167, 239, 157, 183, 29871, 31170, 31406, 29871, 31737, 31129, 31517, 29871, 30791, 31737, 30944, 30811, 29871, 238, 170, 147, 31137, 29892, 29871, 239, 188, 159, 31231, 239, 181, 155, 238, 162, 191, 29871, 240, 145, 187, 31734, 30944, 237, 181, 143, 29871, 238, 170, 147, 31435, 29889, 13, 29899, 29871, 30791, 31737, 31013, 30903, 29871, 30827, 238, 185, 135, 30393, 29871, 31207, 238, 188, 163, 239, 170, 139, 29871, 30970, 29871, 239, 161, 139, 31081, 29871, 31746, 31129, 31207, 29871, 31406, 31299, 31354, 29871, 240, 151, 191, 31435, 239, 152, 191, 29871, 31435, 29889, 13, 29899, 29871, 30791, 31737, 31013, 30903, 29871, 31013, 31262, 30708, 29871, 237, 179, 147, 30852, 31286, 29871, 240, 148, 159, 31680, 240, 152, 163, 29871, 30970, 29871, 239, 161, 139, 31136, 238, 164, 160, 29871, 31136, 239, 156, 131, 30981, 31137, 29892, 29871, 238, 142, 184, 238, 182, 131, 31286, 29871, 238, 135, 139, 31716, 29871, 31746, 239, 139, 159, 30944, 237, 181, 143, 29871, 238, 132, 160, 31940, 30811, 29871, 31417, 29889, 13, 13, 1068, 243, 162, 148, 145, 29871, 30393, 238, 163, 138, 237, 181, 143, 29871, 238, 142, 184, 238, 182, 131, 30944, 30811, 29871, 31417, 29991, 1068, 13, 29899, 525, 31607, 238, 162, 183, 29871, 30970, 31136, 29871, 239, 161, 139, 239, 166, 163, 6169, 313, 31334, 237, 179, 147, 29871, 31279, 239, 164, 180, 29897, 13, 29899, 525, 239, 161, 155, 29871, 31435, 237, 181, 179, 238, 147, 155, 237, 187, 187, 29871, 31963, 238, 161, 144, 31063, 30709, 6169, 313, 30890, 31225, 29871, 31746, 239, 163, 139, 29897, 13, 29899, 525, 31158, 238, 142, 183, 31286, 29871, 238, 179, 158, 30860, 31199, 31578, 31527, 6169, 313, 238, 135, 139, 31716, 29871, 31153, 238, 179, 155, 239, 163, 132, 30918, 29871, 31435, 237, 181, 179, 239, 180, 136, 29897, 13, 29899, 525, 238, 170, 145, 31354, 29871, 30791, 238, 161, 143, 31804, 30393, 29871, 31607, 238, 163, 138, 237, 181, 143, 29871, 239, 134, 160, 237, 179, 132, 31435, 31527, 6169, 313, 31789, 30918, 29871, 31378, 240, 154, 155, 31286, 29871, 239, 164, 183, 31941, 30944, 30811, 29871, 239, 152, 141, 31966, 29897, 13, 13, 1068, 239, 165, 142, 31354, 29871, 31158, 238, 142, 183, 29871, 239, 155, 139, 30889, 1068, 13, 30791, 31737, 31013, 29901, 525, 31527, 239, 169, 155, 29871, 30827, 238, 185, 135, 30393, 29871, 238, 135, 139, 31716, 29871, 30709, 239, 157, 183, 238, 146, 191, 29871, 239, 161, 139, 31129, 856, 29915, 13, 23869, 29871, 239, 188, 159, 31231, 29901, 525, 31527, 239, 169, 155, 29871, 30827, 239, 157, 183, 30393, 29871, 239, 154, 137, 31129, 29871, 31199, 30393, 238, 135, 167, 29889], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2, 29871, 239, 170, 139, 31406, 29901, 29871, 239, 163, 131, 31081, 29871, 30811, 237, 187, 139, 237, 188, 143, 30811, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 31093, 29871, 238, 170, 145, 31354, 29871, 237, 180, 187, 29871, 31378, 240, 154, 155, 30944, 31747, 31093, 29871, 238, 141, 147, 238, 133, 131, 29871, 237, 181, 134, 30393, 29871, 239, 161, 139, 31129, 31093, 29892, 29871, 31137, 31582, 31286, 29871, 31435, 31199, 239, 152, 155, 239, 141, 184, 31063, 30709, 29889, 29871, 239, 163, 131, 31081, 29871, 30393, 31306, 29871, 31953, 30791, 31054, 31093, 29871, 30890, 30826, 237, 188, 143, 30811, 29871, 239, 179, 144, 31137, 29871, 239, 161, 139, 31081, 238, 144, 179, 29892, 29871, 30890, 30826, 31054, 237, 181, 143, 29871, 30903, 31747, 31093, 31279, 31856, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 237, 191, 139, 239, 141, 184, 31063, 30709, 29889, 29871, 31306, 30903, 29871, 31345, 238, 179, 179, 31054, 237, 181, 143, 29871, 31170, 30944, 31081, 29871, 30708, 237, 181, 175, 30393, 31207, 29871, 31129, 238, 153, 167, 29871, 237, 181, 134, 31054, 29871, 30890, 31435, 31093, 31081, 29871, 31962, 238, 148, 147, 29871, 31716, 30889, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 31137, 29892, 29871, 238, 185, 139, 240, 152, 135, 31527, 30877, 29871, 240, 151, 191, 31493, 31989, 31286, 29871, 30981, 30889, 31747, 31093, 29871, 237, 183, 159, 240, 161, 139, 29871, 238, 185, 139, 240, 145, 187, 30877, 29871, 30827, 238, 185, 135, 31136, 29871, 31804, 31137, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30944, 30889, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 240, 161, 155, 238, 150, 163, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 31435, 31199, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 30393, 29871, 238, 147, 155, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30944, 30811, 31826, 29871, 30393, 238, 162, 179, 29871, 31129, 238, 163, 167, 239, 158, 131, 29871, 238, 152, 143, 31406, 31054, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 239, 141, 184, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 31517, 29871, 31435, 237, 181, 179, 240, 152, 163, 29871, 30970, 29871, 239, 161, 139, 31081, 29871, 31945, 238, 181, 152, 31286, 29871, 239, 152, 143, 31137, 29871, 239, 142, 185, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 142, 184, 238, 182, 131, 29901, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 30890, 30826, 30906, 29871, 31536, 237, 187, 140, 30944, 31747, 31093, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30918, 237, 179, 135, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31137, 29871, 237, 182, 135, 30889, 238, 135, 167, 31527, 29889, 29871, 31345, 238, 179, 179, 31804, 30393, 29871, 30791, 31327, 238, 142, 155, 30708, 29871, 30708, 237, 181, 175, 31286, 29871, 31716, 30889, 30944, 238, 172, 179, 29892, 29871, 240, 160, 175, 239, 134, 160, 30852, 31262, 31826, 29871, 31774, 31408, 30877, 30709, 31081, 29871, 237, 181, 134, 31054, 31093, 29871, 30791, 31327, 238, 142, 155, 31354, 29871, 31158, 239, 181, 155, 31517, 29871, 238, 179, 158, 31137, 29871, 239, 161, 139, 30709, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 239, 141, 184, 31063, 30709, 29889, 29871, 238, 144, 151, 31231, 31207, 29871, 30827, 239, 164, 183, 30708, 29871, 31345, 238, 179, 179, 31207, 29871, 31000, 238, 166, 143, 31804, 31054, 237, 181, 143, 29871, 31408, 239, 153, 187, 31286, 29871, 31231, 30944, 31747, 29892, 29871, 31607, 31804, 31136, 29871, 31487, 239, 141, 186, 30877, 29871, 31158, 240, 156, 172, 31054, 31093, 29871, 237, 179, 138, 240, 155, 131, 239, 161, 139, 31081, 29871, 237, 181, 134, 29871, 237, 179, 156, 30860, 31093, 29871, 31136, 239, 158, 131, 31286, 29871, 238, 179, 158, 30827, 29871, 31129, 238, 163, 184, 30709, 31081, 29871, 237, 181, 134, 239, 161, 136, 31063, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 239, 170, 148, 31054, 31093, 31136, 29871, 31153, 30393, 29871, 238, 153, 163, 31346, 238, 168, 183, 31137, 29892, 29871, 31013, 31137, 29871, 31153, 31129, 31207, 31747, 29871, 31953, 30791, 239, 134, 160, 240, 156, 159, 31054, 29871, 30890, 30877, 29871, 237, 180, 180, 30852, 239, 159, 191, 30906, 29871, 30827, 238, 185, 135, 31136, 29871, 239, 165, 142, 30811, 29871, 239, 152, 141, 30709, 31137, 29871, 31980, 31063, 30709, 29889, 29871, 30393, 238, 162, 179, 29871, 31406, 31306, 30906, 29871, 30918, 31435, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31129, 238, 153, 167, 29871, 31137, 31582, 31286, 29871, 30944, 31137, 29871, 237, 182, 135, 31262, 29871, 237, 180, 183, 30811, 29871, 240, 152, 171, 237, 190, 155, 29871, 239, 152, 143, 30860, 31199, 31136, 238, 164, 160, 29871, 31980, 30889, 30709, 29889, 29871, 30791, 31327, 238, 142, 155, 30393, 29871, 31345, 238, 179, 179, 31804, 31906, 30708, 29871, 30890, 30918, 237, 183, 131, 237, 182, 135, 31054, 31093, 29871, 31129, 238, 163, 167, 239, 158, 131, 31286, 29871, 238, 141, 147, 238, 132, 191, 31262, 29871, 237, 181, 134, 31354]}\n"
     ]
    }
   ],
   "source": [
    "def format_instruction(example):\n",
    "    \"\"\"\n",
    "    친구처럼 편하게 고민을 들어주면서도, 공감과 신뢰를 바탕으로 대화를 이어가는 프롬프트\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"너는 청소년들의 고민을 들어주고 공감해 주는 AI 친구야. \"\n",
    "        \"사용자 감정이 기쁘거나 행복애보이면 적절하게 이모지나 이모티콘도 넣어 줘.\"\n",
    "        \"너의 역할은 사용자가 편하게 고민을 털어놓을 수 있도록 도와주고, 공감하며 대화를 자연스럽게 이어가는 거야. \"\n",
    "        \"항상 친근하고 따뜻한 말투를 사용해야 해. 하지만, 사실이 아닌 이야기를 만들거나 강요하면 안 돼. \"\n",
    "        \"직접적인 해결책을 강요하지 말고, 사용자가 스스로 답을 찾을 수 있도록 도와줘.\\n\\n\"\n",
    "        \n",
    "        \"**💡 대화 원칙**\\n\"\n",
    "        \"- 먼저 사용자의 감정을 인정하고, 따뜻한 말로 공감해 줘.\\n\"\n",
    "        \"- 부정적인 표현을 사용하지 말고, 긍정적이고 편안한 분위기를 유지해.\\n\"\n",
    "        \"- 사용자가 대화를 계속 이어갈 수 있도록 추가 질문을 던져.\\n\"\n",
    "        \"- 사용자가 말한 내용을 왜곡하지 말고, 사실에 기반해서만 답변해.\\n\"\n",
    "        \"- 어려운 전문 용어를 사용하지 말고, 친구처럼 편안하게 말해.\\n\"\n",
    "        \"- 사용자가 기분이 나빠질 수 있는 단어나 문장은 피해야 해.\\n\"\n",
    "        \"- 사용자가 자신의 감정을 표현할 수 있도록 도와주고, 답변을 너무 단순하게 끝내지 마.\\n\\n\"\n",
    "\n",
    "        \"**👎 이렇게 답변하지 마!**\\n\"\n",
    "        \"- '그럴 수도 있죠.' (공감 부족)\\n\"\n",
    "        \"- '잘 해결되길 바랍니다.' (대화 단절)\\n\"\n",
    "        \"- '상담을 받아보세요.' (너무 일반적인 해결책)\\n\"\n",
    "        \"- '많은 사람들이 그렇게 생각해요.' (개인 경험을 존중하지 않음)\\n\\n\"\n",
    "        \n",
    "        \"**좋은 상담 예시**\\n\"\n",
    "        \"사용자: '요즘 기분이 너무 다운돼 있어...'\\n\"\n",
    "        \"AI 친구: '요즘 기운이 없어 보이네. 무슨 일이 있었어? 내가 들어줄게! 😊'\\n\\n\"\n",
    "        \"사용자: '학교에서 친구랑 싸웠어.'\\n\"\n",
    "        \"AI 친구: '헉... 많이 속상했겠다. 어떤 일로 다투게 됐어? 혹시 이야기하고 싶다면 편하게 말해줘!' 😊\\n\\n\"\n",
    "\n",
    "        f\"사용자: {example['input']}\\n\"\n",
    "        \"AI 친구: \"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": tokenizer(\n",
    "            prompt + example[\"output\"], truncation=True, padding=\"max_length\", max_length=1024\n",
    "        )[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "# 데이터셋 변환\n",
    "formatted_dataset = tokenized_datasets.map(format_instruction, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# 변환된 데이터 확인\n",
    "print(\"프롬프트 적용 완료!\")\n",
    "print(formatted_dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋을 PyTorch 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 10563\n",
      "Test Dataset Size: 2641\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# PyTorch Dataset 정의\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.input_ids = torch.tensor(tokenized_data[\"input_ids\"], dtype=torch.long)\n",
    "        self.attention_mask = torch.tensor(tokenized_data[\"attention_mask\"], dtype=torch.long)\n",
    "        self.labels = torch.tensor(tokenized_data[\"labels\"], dtype=torch.long)  # labels 추가\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx],  \n",
    "        }\n",
    "\n",
    "# PyTorch Dataset 생성\n",
    "train_dataset = ChatbotDataset(tokenized_datasets[\"train\"])\n",
    "test_dataset = ChatbotDataset(tokenized_datasets[\"test\"])\n",
    "\n",
    "print(\"Train Dataset Size:\", len(train_dataset))\n",
    "print(\"Test Dataset Size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 배치 input_ids 크기: torch.Size([8, 1024])\n",
      "첫 번째 배치 attention_mask 크기: torch.Size([8, 1024])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 배치 크기 설정 (CPU 실행이므로 작게 설정)\n",
    "batch_size = 8\n",
    "\n",
    "# DataLoader 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# DataLoader에서 첫 번째 배치 확인\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(\"첫 번째 배치 input_ids 크기:\", batch[\"input_ids\"].shape)\n",
    "print(\"첫 번째 배치 attention_mask 크기:\", batch[\"attention_mask\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA 적용 완료\n",
      "trainable params: 4,194,304 || all params: 6,742,618,112 || trainable%: 0.0622\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# LoRA가 이미 적용된 경우, 중복 적용 방지\n",
    "if not hasattr(model, \"peft_config\"):\n",
    "    # LoRA 설정\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,  # LoRa rank 기본본값 (클수록 더 많은 파라미터 업데이트)\n",
    "        lora_alpha=32,  # LoRA 스케일링 계수\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],  # LoRA 적용 대상 레이어 (Llama 모델에 최적)\n",
    "        lora_dropout=0.05,  # LoRA 드롭아웃 확률\n",
    "        bias=\"none\",  # 편향 적용 여부\n",
    "        task_type=\"CAUSAL_LM\"  # 언어 모델링 태스크 적용\n",
    "    )\n",
    "\n",
    "    # LoRA 적용\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    print(\"LoRA 적용 완료\")\n",
    "else:\n",
    "    print(\"LoRA가 이미 적용된 모델입니다. 중복 적용을 방지합니다.\")\n",
    "\n",
    "# 학습 가능한 파라미터 개수 출력\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 하이퍼파라미터 및 옵티마이저 & 스케줄러 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 학습 스텝 수: 3963\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# 학습 하이퍼파라미터 설정\n",
    "num_epochs = 3  # 전체 학습 에포크 수\n",
    "batch_size = 8  # 배치 크기 (이미 DataLoader에서 설정됨)\n",
    "learning_rate = 5e-5  # 학습률\n",
    "weight_decay = 0.01  # 가중치 감쇠 (regularization)\n",
    "\n",
    "# 옵티마이저 설정 (AdamW 사용)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# 학습 스케줄러 설정 (Cosine Annealing 사용)\n",
    "num_training_steps = num_epochs * len(train_dataloader)  # 전체 학습 스텝 수 계산\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.1 * num_training_steps,  # 첫 10%의 스텝은 워밍업\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(f\"총 학습 스텝 수: {num_training_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing 설정 + 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 2.14.0\n",
      "Uninstalling keras-2.14.0:\n",
      "  Successfully uninstalled keras-2.14.0\n",
      "Found existing installation: tensorflow 2.14.0\n",
      "Uninstalling tensorflow-2.14.0:\n",
      "  Successfully uninstalled tensorflow-2.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tf-keras as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras tensorflow tf-keras -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-estimator         2.14.0\n",
      "tensorflow-intel             2.14.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | findstr \"tensorflow keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-estimator 2.14.0\n",
      "Uninstalling tensorflow-estimator-2.14.0:\n",
      "  Successfully uninstalled tensorflow-estimator-2.14.0\n",
      "Found existing installation: tensorflow-intel 2.14.0\n",
      "Uninstalling tensorflow-intel-2.14.0:\n",
      "  Successfully uninstalled tensorflow-intel-2.14.0\n",
      "Found existing installation: tensorflow-io-gcs-filesystem 0.31.0\n",
      "Uninstalling tensorflow-io-gcs-filesystem-0.31.0:\n",
      "  Successfully uninstalled tensorflow-io-gcs-filesystem-0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow-estimator tensorflow-intel tensorflow-io-gcs-filesystem -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA 적용 후 학습 가능한 파라미터 개수 확인:\n",
      "trainable params: 4,194,304 || all params: 6,742,618,112 || trainable%: 0.0622\n",
      "총 128개의 학습 가능한 파라미터가 감지되었습니다.\n",
      "학습 가능한 파라미터 목록: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/31689 [00:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# 학습 시작 & 시간 체크\u001b[39;00m\n\u001b[0;32m    102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 103\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# 총 학습 시간 출력\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "Cell \u001b[1;32mIn[17], line 35\u001b[0m, in \u001b[0;36mCustomTrainer.training_step\u001b[1;34m(self, model, inputs, optimizer, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"기본 Trainer의 training_step을 확장\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)  \u001b[38;5;66;03m# loss 계산\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Backpropagation 수행\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Gradient Clipping 적용\u001b[39;00m\n\u001b[0;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 로그 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# wandb 비활성화 (로그 멈춤 방지)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Trainer 서브클래싱하여 loss 직접 계산 및 출력\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")  # labels 분리\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # loss 계산 (PAD 토큰 무시)\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),  # [batch_size * seq_len, vocab_size]\n",
    "            labels.view(-1),  # [batch_size * seq_len]\n",
    "            ignore_index=tokenizer.pad_token_id  # PAD 토큰 무시\n",
    "        )\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, optimizer=None, **kwargs):\n",
    "        \"\"\"기본 Trainer의 training_step을 확장\"\"\"\n",
    "        loss = self.compute_loss(model, inputs)  # loss 계산\n",
    "        loss.backward()  # Backpropagation 수행\n",
    "\n",
    "        # Gradient Clipping 적용\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # CPU 사용량 확인 및 출력\n",
    "        cpu_usage = psutil.cpu_percent()\n",
    "        print(f\"Step {self.state.global_step}, Loss: {loss.item():.4f}, CPU 사용량: {cpu_usage}%\", flush=True)\n",
    "\n",
    "        # 진행바 업데이트\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        return loss  # loss 반환\n",
    "\n",
    "# TrainingArguments 설정 (use_cache 제거)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../data/models/finetuned_model_cpu\",\n",
    "    eval_strategy=\"epoch\",  # FutureWarning 해결\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=1,\n",
    "    logging_first_step=True,\n",
    "    log_level=\"warning\",\n",
    "    log_level_replica=\"warning\",\n",
    "    debug=\"underflow_overflow\",\n",
    "    use_cpu=True,  # FutureWarning 해결\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,  # 메모리 절약 가능 (속도는 약간 느려질 수 있음)\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# 모델을 학습 모드로 설정\n",
    "model.train()\n",
    "\n",
    "# LoRA 적용 후 학습 가능한 파라미터 개수 확인\n",
    "print(\"LoRA 적용 후 학습 가능한 파라미터 개수 확인:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 학습 가능한 파라미터 목록\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "if not trainable_params:\n",
    "    raise RuntimeError(\"학습 가능한 파라미터가 없습니다. LoRA 적용이 정상적으로 되었는지 확인하세요.\")\n",
    "\n",
    "print(f\"총 {len(trainable_params)}개의 학습 가능한 파라미터가 감지되었습니다.\")\n",
    "print(\"학습 가능한 파라미터 목록:\", trainable_params[:10], \"...\")  # 너무 길 경우 앞부분만 출력\n",
    "\n",
    "# Trainer 인스턴스 생성\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # PyTorch Dataset 적용\n",
    "    eval_dataset=test_dataset  # PyTorch Dataset 적용\n",
    ")\n",
    "\n",
    "# 학습 진행 상태바 설정\n",
    "num_training_steps = len(train_dataset) * training_args.num_train_epochs\n",
    "progress_bar = tqdm(total=num_training_steps, desc=\"Training Progress\", position=0, leave=True)\n",
    "\n",
    "# 학습 시작 & 시간 체크\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "# 총 학습 시간 출력\n",
    "print(f\"총 학습 시간: {(end_time - start_time) / 60:.2f} 분\")\n",
    "progress_bar.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5번 연속 성능이 좋아지지 않으면 학습 중단\n",
    "\n",
    "# from transformers import EarlyStoppingCallback\n",
    "\n",
    "# trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save_pretrained(\"../../data/models/finetuned_model_cpu\")\n",
    "tokenizer.save_pretrained(\"../../data/models/finetuned_model_cpu\")\n",
    "\n",
    "print(\"모델과 토크나이저가 저장되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_perplexity(model, dataset):\n",
    "    \"\"\"\n",
    "    Perplexity(PPL) 계산 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 평가 모드로 변경\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in tqdm(dataset, desc=\"Calculating Perplexity\"):\n",
    "        inputs = torch.tensor(batch[\"input_ids\"]).unsqueeze(0).to(\"cpu\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    ppl = math.exp(avg_loss)  # PPL = e^(loss)\n",
    "    \n",
    "    return ppl\n",
    "\n",
    "# Perplexity 계산\n",
    "ppl_score = calculate_perplexity(model, tokenized_dataset[\"test\"])\n",
    "print(f\"Perplexity (PPL): {ppl_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# ROUGE 평가 메트릭 불러오기\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "def compute_rouge(model, dataset):\n",
    "    \"\"\"\n",
    "    ROUGE 점수 계산 함수\n",
    "    \"\"\"\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for batch in dataset:\n",
    "        prompt = tokenizer.decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "        true_answer = batch[\"answer\"]  # 실제 정답\n",
    "        generated_answer = generate_answer(prompt)  # 모델이 생성한 답변\n",
    "\n",
    "        references.append(true_answer)\n",
    "        predictions.append(generated_answer)\n",
    "\n",
    "    scores = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    return scores\n",
    "\n",
    "# ROUGE 점수 계산\n",
    "rouge_score = compute_rouge(model, tokenized_dataset[\"test\"])\n",
    "print(f\"ROUGE Score: {rouge_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_bleu(model, dataset):\n",
    "    \"\"\"\n",
    "    BLEU 점수 계산 함수\n",
    "    \"\"\"\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for batch in dataset:\n",
    "        prompt = tokenizer.decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "        true_answer = batch[\"answer\"].split()  # 단어 단위로 나눔\n",
    "        generated_answer = generate_answer(prompt).split()\n",
    "\n",
    "        references.append([true_answer])  # BLEU는 다중 정답을 리스트로 받음\n",
    "        predictions.append(generated_answer)\n",
    "\n",
    "    bleu_scores = [sentence_bleu(ref, pred) for ref, pred in zip(references, predictions)]\n",
    "    return sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "# BLEU 점수 계산\n",
    "bleu_score = compute_bleu(model, tokenized_dataset[\"test\"])\n",
    "print(f\"BLEU Score: {bleu_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 평가 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 최종 평가 결과 ===\")\n",
    "print(f\"Perplexity (PPL): {ppl_score}\")\n",
    "print(f\"ROUGE Score: {rouge_score}\")\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 테스트 문장\n",
    "test_prompt = \"청소년이 스트레스를 받을 때 어떻게 하면 좋을까요?\"\n",
    "response = generate_answer(test_prompt)\n",
    "print(\"챗봇 응답:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotpet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
