{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuda 사용여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: False\n",
      "현재 사용 중인 디바이스: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 현재 GPU 사용 여부 확인\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"현재 사용 중인 디바이스:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow 비활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"USE_TF\"] = \"0\"  # TensorFlow 강제 비활성화\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅 페이스 cli 설치 및 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d9f5f4279a482e884f9fa89cd4b005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (4.48.3)\n",
      "Collecting peft\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.14.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch transformers peft datasets tqdm accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 허깅페이스에서 모델을 다운로드하고 로컬에 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qwen/Qwen2-7B-Instruct\n",
    "    - https://github.com/QwenLM/Qwen\n",
    "    - https://huggingface.co/Qwen/Qwen2-7B-Instruct/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blobfile\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from blobfile) (2.3.0)\n",
      "Collecting lxml>=4.9 (from blobfile)\n",
      "  Downloading lxml-5.3.1-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock>=3.0 in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (from blobfile) (3.17.0)\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 23.5 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.1-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.8/3.8 MB 45.4 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, pycryptodomex, lxml, blobfile\n",
      "Successfully installed blobfile-3.0.0 lxml-5.3.1 pycryptodomex-3.21.0 sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install blobfile sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\envs\\robotpet\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade sentencepiece\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다운로드 코드 한번만 실행...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 다운로드 시도 1/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dd5dbae3df40c5aaa71a9561b2fe48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\robotpet\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-7B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d523de3642d45ca9192982f9acb51c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e82050d30304418b9a01ef43b4ccb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af2959cfdbd4191adbec1d49a73ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e458317c4b48d797b40f14a8f7af4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c31ab579214c5c9089f6a9b9c61c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7693fdf6254fe08b74a3b48ef0d8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be8a6af9fee4233a55320c2a05cbba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c53bab1969d45439743192877fd3928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de152dbd679e446287d5cda7cbd72193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add6d25381964abb85a6e59e38644ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d9268299514ec6a0104abcffc79dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e9575ee40e4c3cbd64fd6e4f8a40fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 '../../data/models/Qwen2-7B-Instruct' 경로에 성공적으로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 다운로드 시간 제한을 환경 변수로 설정 (10분)\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"600\"\n",
    "\n",
    "# 모델명 지정 (Hugging Face에서 다운로드)\n",
    "model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "# 모델 저장 경로\n",
    "save_path = \"../../data/models/Qwen2-7B-Instruct\"\n",
    "\n",
    "# 모델 다운로드 (재시도 기능 추가)\n",
    "def load_model_with_retry(model_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"모델 다운로드 시도 {attempt + 1}/{max_retries}...\")\n",
    "\n",
    "            # 모델 및 토크나이저 다운로드 (Qwen 모델은 trust_remote_code=True 필요)\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "            # 모델 & 토크나이저 로컬 저장\n",
    "            model.save_pretrained(save_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "\n",
    "            print(f\"모델이 '{save_path}' 경로에 성공적으로 저장되었습니다!\")\n",
    "            return model, tokenizer  # 성공 시 반환\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(\"다시 시도 중...\")\n",
    "            else:\n",
    "                print(\"모델 다운로드 실패. 인터넷 연결 확인 또는 수동 다운로드 필요.\")\n",
    "                raise e\n",
    "\n",
    "# 모델 다운로드 및 저장 실행\n",
    "model, tokenizer = load_model_with_retry(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 컬럼명: ['input', 'output', 'input_length', 'output_length']\n",
      "Train 데이터 개수: 10563\n",
      "Test 데이터 개수: 2641\n",
      "샘플 데이터: {'input': '저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.', 'output': '사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다. 이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다. 이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.', 'input_length': 362, 'output_length': 1015}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# CSV 파일 경로\n",
    "data_path = \"../../data/total_kor_counsel_bot_clean.csv\"\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_path)\n",
    "\n",
    "# 데이터 80:20으로 나누기 (train 80%, test 20%)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(\"데이터 컬럼명:\", dataset[\"train\"].column_names)\n",
    "print(\"Train 데이터 개수:\", len(dataset[\"train\"]))\n",
    "print(\"Test 데이터 개수:\", len(dataset[\"test\"]))\n",
    "\n",
    "# 데이터 샘플 확인 (첫 번째 데이터 출력)\n",
    "print(\"샘플 데이터:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_length 확인 (모델이 감당할 수 있는 최대 토큰 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568a6f5f58ee42ce82cb6e5fae2b79b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 최대 토큰 길이: 32768\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# 모델 불러오기 (로딩 시간 단축을 위해 weights만 확인)\n",
    "MODEL_NAME = \"Qwen/Qwen2-7B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# 모델의 최대 토큰 길이 확인\n",
    "print(\"모델 최대 토큰 길이:\", model.config.max_position_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vram이 충분하면 데이터가 길어도 그대로 학습해도 될 것 같긴 한데 청크 분할 + LoRA + 4-bit 양자화 병행이 적절해 보임임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청크 분할 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터의 토큰 길이 확인 (앞 10개 샘플)\n",
      "샘플 1: 589 tokens\n",
      "샘플 2: 690 tokens\n",
      "샘플 3: 599 tokens\n",
      "샘플 4: 568 tokens\n",
      "샘플 5: 508 tokens\n",
      "샘플 6: 525 tokens\n",
      "샘플 7: 480 tokens\n",
      "샘플 8: 471 tokens\n",
      "샘플 9: 599 tokens\n",
      "샘플 10: 473 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"원본 데이터의 토큰 길이 확인 (앞 10개 샘플)\")\n",
    "for i in range(10):\n",
    "    text = dataset[\"train\"][i][\"output\"]  # 원본 답변 데이터\n",
    "    token_length = len(tokenizer(text)[\"input_ids\"])\n",
    "    print(f\"샘플 {i+1}: {token_length} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 최대 토큰 길이가 생각보다 길어서 이게 필요할까 고민하긴 했는데 VRAM 문제 우려로 인해 청크 단위로 나눠서 학습\n",
    "- 문장들을 문장 단위로 나눠서 256 토큰 넘으면 새로운 청크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac5a68084b644a6be56563df51749a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c890016e7864440ab6115cf7cbf26dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 적용 후 데이터셋 컬럼: {'train': ['input', 'output', 'input_length', 'output_length'], 'test': ['input', 'output', 'input_length', 'output_length']}\n",
      "\n",
      "각 청크의 토큰 길이 확인 (앞 10개 샘플)\n",
      "\n",
      "샘플 1 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 216 tokens\n",
      "  output 청크 1: 221 tokens\n",
      "  output 청크 2: 223 tokens\n",
      "  output 청크 3: 147 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 2 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 140 tokens\n",
      "  output 청크 1: 247 tokens\n",
      "  output 청크 2: 244 tokens\n",
      "  output 청크 3: 201 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 3 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 79 tokens\n",
      "  output 청크 1: 240 tokens\n",
      "  output 청크 2: 217 tokens\n",
      "  output 청크 3: 142 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 4 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 177 tokens\n",
      "  output 청크 1: 230 tokens\n",
      "  output 청크 2: 236 tokens\n",
      "  output 청크 3: 103 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 5 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 38 tokens\n",
      "  output 청크 1: 225 tokens\n",
      "  output 청크 2: 240 tokens\n",
      "  output 청크 3: 44 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 6 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 101 tokens\n",
      "  output 청크 1: 215 tokens\n",
      "  output 청크 2: 233 tokens\n",
      "  output 청크 3: 77 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 7 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 85 tokens\n",
      "  output 청크 1: 221 tokens\n",
      "  output 청크 2: 233 tokens\n",
      "  output 청크 3: 27 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 8 (input 청크 개수: 1, output 청크 개수: 2)\n",
      "  input 청크 1: 114 tokens\n",
      "  output 청크 1: 221 tokens\n",
      "  output 청크 2: 250 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 9 (input 청크 개수: 1, output 청크 개수: 3)\n",
      "  input 청크 1: 63 tokens\n",
      "  output 청크 1: 229 tokens\n",
      "  output 청크 2: 228 tokens\n",
      "  output 청크 3: 144 tokens\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 10 (input 청크 개수: 1, output 청크 개수: 2)\n",
      "  input 청크 1: 147 tokens\n",
      "  output 청크 1: 231 tokens\n",
      "  output 청크 2: 243 tokens\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "MAX_TOKENS = 256  # 최대 토큰 길이 설정\n",
    "\n",
    "def chunk_text(example):\n",
    "    \"\"\"input과 output을 문장 단위로 분할하여 청크화\"\"\"\n",
    "    if not isinstance(example[\"output\"], str) or not isinstance(example[\"input\"], str):\n",
    "        return None  # 유효하지 않은 데이터 무시\n",
    "    \n",
    "    def split_into_chunks(text):\n",
    "        \"\"\"문장을 분할하고, 토큰 길이를 기준으로 청크화\"\"\"\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())  # 문장 단위로 분할\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            tokenized_sentence = tokenizer(sentence, add_special_tokens=False)[\"input_ids\"]\n",
    "            token_length = len(tokenized_sentence)\n",
    "\n",
    "            if current_length + token_length > MAX_TOKENS:\n",
    "                if current_chunk:\n",
    "                    chunks.append(\" \".join(current_chunk))  # 이전 청크 저장\n",
    "                current_chunk = [sentence]  # 새로운 청크 시작\n",
    "                current_length = token_length\n",
    "\n",
    "            else:\n",
    "                current_chunk.append(sentence)\n",
    "                current_length += token_length\n",
    "\n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))  # 마지막 청크 추가\n",
    "\n",
    "        return chunks if chunks else [text]  # 빈 리스트 방지\n",
    "\n",
    "    # input과 output 각각 청크화 적용\n",
    "    input_chunks = split_into_chunks(example[\"input\"])\n",
    "    output_chunks = split_into_chunks(example[\"output\"])\n",
    "\n",
    "    return {\"input\": input_chunks, \"output\": output_chunks}  # 리스트 형태로 반환\n",
    "\n",
    "# 데이터셋 필터링 후 청크 분할 적용\n",
    "dataset = dataset.filter(lambda x: isinstance(x[\"input\"], str) and isinstance(x[\"output\"], str))  # 유효한 데이터만 필터링\n",
    "chunked_dataset = dataset.map(chunk_text, batched=False, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# 데이터셋 컬럼 확인\n",
    "print(\"청크 적용 후 데이터셋 컬럼:\", chunked_dataset.column_names)\n",
    "\n",
    "# 청크 개수 및 길이 확인\n",
    "print(\"\\n각 청크의 토큰 길이 확인 (앞 10개 샘플)\")\n",
    "\n",
    "for i in range(10):\n",
    "    chunked_texts_input = chunked_dataset[\"train\"][i][\"input\"]  # input 청크 리스트\n",
    "    chunked_texts_output = chunked_dataset[\"train\"][i][\"output\"]  # output 청크 리스트\n",
    "\n",
    "    print(f\"\\n샘플 {i+1} (input 청크 개수: {len(chunked_texts_input)}, output 청크 개수: {len(chunked_texts_output)})\")\n",
    "\n",
    "    for j, chunk in enumerate(chunked_texts_input):\n",
    "        token_length = len(tokenizer(chunk)[\"input_ids\"])\n",
    "        print(f\"  input 청크 {j+1}: {token_length} tokens\")\n",
    "\n",
    "    for k, chunk in enumerate(chunked_texts_output):\n",
    "        token_length = len(tokenizer(chunk)[\"input_ids\"])\n",
    "        print(f\"  output 청크 {k+1}: {token_length} tokens\")\n",
    "\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 컬럼: {'train': ['input', 'output', 'input_length', 'output_length'], 'test': ['input', 'output', 'input_length', 'output_length']}\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋 컬럼:\", chunked_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 10563\n",
      "Test 데이터 개수: 2641\n",
      "\n",
      "샘플 1:\n",
      "질문: ['저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.']\n",
      "답변: ['사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다.', '이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다.', '이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.']\n",
      "--------------------------------------------------\n",
      "\n",
      "샘플 2:\n",
      "질문: ['최근에 학교에서 일이 많아져서 무척 바쁩니다. 시간이 없어서 잠을 충분히 못 자고, 집에 가면 공부와 과제로 바빠서 아침에 일어나는 것도 힘들어요. 그리고 지난 주말에도 회사 일로 인해 일을 해야 했는데, 몸이 아프고 이제는 정말 지쳐서 공부도 하기 싫어요. 이대로는 과제도 못 끝내고 시험도 잘 볼 수 없을 것 같아서 걱정이에요. 어떻게 하면 좋을까요?']\n",
      "답변: ['사우님 최근 학교 일과 직장 일로 인해 정말 바쁘게 지내고 있으시네요. 시간이 부족해서 잠도 충분히 자지 못하고 공부와 과제로 인해 집에서의 휴식시간도 없는 상황입니다. 지난 주말에도 회사 일로 인해 일을 해야 했는데 이를 계속해서 이어가면 몸이 힘들어져서 지금은 공부도 하기 싫다는 생각을 하고 계시다고 하셨습니다. 이대로 계속 하면 과제도 못 끝내고 시험도 잘 볼 수 없을 것 같다는 걱정을 하시는 것 같아요. 함께 해결해보아요. 사우님 최근 학교 일과 직장 일로 인해 과제, 시험, 일 모두 끝나지 않는 바쁜 일상을 보내고 계십니다. 공부를 위한 휴식 시간이 없어지면 피로 증세가 나타나고 수면의 질이 떨어지면서 정신적으로도 지칠 수 있습니다.', '이런 상황이 계속되면 스트레스가 증가하면서 집중력이 떨어지게 되고 실력 저하로 이어질 수 있습니다. 정신적인 부담이 계속해서 느껴지면 이후의 일도 처리하기 어려워지기 때문에 최대한 자신을 아끼는 것이 좋습니다. 사우님 지금 상황에서는 자신이 돌보는 것이 최우선입니다. 최근 과업이 많아진 것 같아요. 이런 일상에서 조금 더 체계적으로 규칙적인 생활을 유지하는 것이 중요합니다. 체력적, 정신적으로 지치신 상황이니 체력을 유지하기 위해 규칙적인 식사와 수면 시간을 확보하시고 충분한 수면과 휴식을 취해주세요. 과제와 일의 우선순위를 나누어서 해결할 수 있는 일이 있는지 파악해보세요. 만약 가능하다면 직장에서 일의 부담을 덜어줄 동료나 선배에게 조언을 구해보시는 것도 좋을 것 같아요.', '또한 시간을 쪼개서 자신만의 취미 생활이나 여가 생활을 만드는 것도 추천드려요. 지친 마음을 달래줄 수 있는 행복을 찾아가는 것도 중요하겠죠. 사우님 지금은 일과 공부를 모두 챙기시려다 보니 체력적으로나 정신적으로 힘들어진 상태입니다. 지금 상황에서는 좀 더 자신에게 체념할 필요가 있습니다. 이후 다시 시작할 수 있는 기회를 노리면서 마음을 다스리는 것이 중요합니다. 조금씩 자신의 시간을 만들어가면서 앞으로의 일에 대비할 수 있는 준비를 하면 좋을 것 같아요. 사우님 위의 답변이 조금이나마 도움이 되었기를 바라는 마음입니다. 이후에도 힘든 마음이 계속 되시면 언제든지 저를 찾아주세요. 그럼 좋은 하루 보내세요 :)']\n",
      "--------------------------------------------------\n",
      "\n",
      "샘플 3:\n",
      "질문: ['취업을 하고 나서 회사에서 일을 잘 못했다는 비판과 함께 부정적인 반응을 받으면서 제 자신에게 대한 자신감이 없어졌어요. 저의 역량을 완벽히 뽐내지는 못하는 상황이라면서요. 이런 상황에서 제 자신을 다시 믿을 수 있는 방법이 있을까요?']\n",
      "답변: ['취업을 하고 나서 제 역량을 완벽히 뽐내지는 못하는 상황에서 부정적인 반응을 받고 회사에서 일을 잘못했다는 비판을 받으며 자신감이 떨어진 것 같아요. 이런 상황에서 제 자신을 다시 믿을 수 있는 방법이 있을까요? 사우님의 경우 새로운 환경에서 새로운 일을 하게 되면서 현재 업무에 대한 불확실성과 불안감을 느끼고 있는 것 같습니다. 이로 인해 제 역량을 완벽히 뽐내지 못한다는 생각으로 자존감이 낮아진 것 같습니다. 사우님이 말씀하신 부정적인 반응은 일을 할 때 실수를 했을 때 아무런 도움이 되지 않는 실수 비판입니다. 이러한 비판은 실력보다는 실수를 용서하지 못하고 자신을 자책하는 부정적인 생각을 불러일으키게 됩니다. 이러한 생각을 하다보면 자신에 대한 자신감이 떨어지게 됩니다.', '사우님, 새로운 환경에서 일을 하면서 일을 잘 못 했다는 부정적인 생각이 들 때는 아래와 같은 방법으로 대처할 수 있습니다. - 자신의 장점을 미리 적어보기: 자신이 무엇을 잘하는지 미리 정리해두면 일이 잘 풀릴 때 더욱 자신감이 붙게 됩니다. - 실수를 긍정적인 방향으로 생각하기: 실수는 항상 좋지 않은 것은 아닙니다. 실수를 한다는 것은 새로운 시도를 한다는 것입니다. 실수는 괜찮습니다. 실수를 하면서 무엇을 배우는지 생각해보세요. - 사전에 일의 규칙을 충분히 이해하기: 이전에 비슷한 일을 하던 곳에서는 어떻게 했는지, 이전에 다른 사람들이 이 일을 어떻게 해왔는지, 상사나 동료에게 미리 물어보기 등을 통해서 불안감을 줄일 수 있습니다.', '- 동료나 상사와 이야기하기: 불확실한 점이나 이해하지 못하는 부분을 상사나 동료에게 물어보면 불안감을 줄일 수 있습니다. - 기분전환하기: 무엇을 하면 기분전환이 될까요? 노래듣기, 스트레칭, 환경전환 등등 자신에게 맞는 방법으로 기분을 전환해보세요. 사우님, 위의 답변이 조금이라도 도움이 되었기를 바라는 마음입니다. 이후에도 힘든 마음이 계속되시면 언제든지 저를 찾아주세요. 그럼 좋은 하루 보내세요 :)']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Train 데이터 개수:\", len(chunked_dataset[\"train\"]))\n",
    "print(\"Test 데이터 개수:\", len(chunked_dataset[\"test\"]))\n",
    "\n",
    "# 샘플 데이터 확인 (3개만 출력)\n",
    "for i in range(3):\n",
    "    chunked_input = chunked_dataset[\"train\"][i][\"input\"]  # 질문 (청크된 데이터)\n",
    "    chunked_output = chunked_dataset[\"train\"][i][\"output\"]  # 답변 (청크된 데이터)\n",
    "\n",
    "    print(f\"\\n샘플 {i+1}:\")\n",
    "    print(\"질문:\", chunked_input)\n",
    "    print(\"답변:\", chunked_output)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청크 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Length Statistics:\n",
      "Total Chunks: 30206\n",
      "Mean Length: 198.30 tokens\n",
      "Max Length: 269 tokens\n",
      "Min Length: 1 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 청크 길이 데이터 수집\n",
    "chunk_lengths = []\n",
    "for example in chunked_dataset[\"train\"]:\n",
    "    for chunk in example[\"output\"]:  # \"output\" 컬럼이 청크 데이터일 가능성 높음\n",
    "        tokenized = tokenizer(chunk, add_special_tokens=True)  # 특수토큰 포함\n",
    "        chunk_lengths.append(len(tokenized[\"input_ids\"]))\n",
    "\n",
    "# 텍스트 출력 (기본 통계)\n",
    "print(\"Chunk Length Statistics:\")\n",
    "print(f\"Total Chunks: {len(chunk_lengths)}\")\n",
    "print(f\"Mean Length: {sum(chunk_lengths) / len(chunk_lengths):.2f} tokens\")\n",
    "print(f\"Max Length: {max(chunk_lengths)} tokens\")\n",
    "print(f\"Min Length: {min(chunk_lengths)} tokens\")\n",
    "\n",
    "# 히스토그램 그래프\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(chunk_lengths, bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "plt.xlabel(\"Token Length per Chunk\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Chunk Token Lengths (After Fix)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균적인 청크 길이: 198.30 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"평균적인 청크 길이: {sum(chunk_lengths) / len(chunk_lengths):.2f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 청크 데이터가 질문(input)과 답변(output)의 형식이 올바른지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "샘플 1:\n",
      "질문 (input): ['저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.']\n",
      "답변 (output): ['사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다.', '이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다.', '이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 2:\n",
      "질문 (input): ['최근에 학교에서 일이 많아져서 무척 바쁩니다. 시간이 없어서 잠을 충분히 못 자고, 집에 가면 공부와 과제로 바빠서 아침에 일어나는 것도 힘들어요. 그리고 지난 주말에도 회사 일로 인해 일을 해야 했는데, 몸이 아프고 이제는 정말 지쳐서 공부도 하기 싫어요. 이대로는 과제도 못 끝내고 시험도 잘 볼 수 없을 것 같아서 걱정이에요. 어떻게 하면 좋을까요?']\n",
      "답변 (output): ['사우님 최근 학교 일과 직장 일로 인해 정말 바쁘게 지내고 있으시네요. 시간이 부족해서 잠도 충분히 자지 못하고 공부와 과제로 인해 집에서의 휴식시간도 없는 상황입니다. 지난 주말에도 회사 일로 인해 일을 해야 했는데 이를 계속해서 이어가면 몸이 힘들어져서 지금은 공부도 하기 싫다는 생각을 하고 계시다고 하셨습니다. 이대로 계속 하면 과제도 못 끝내고 시험도 잘 볼 수 없을 것 같다는 걱정을 하시는 것 같아요. 함께 해결해보아요. 사우님 최근 학교 일과 직장 일로 인해 과제, 시험, 일 모두 끝나지 않는 바쁜 일상을 보내고 계십니다. 공부를 위한 휴식 시간이 없어지면 피로 증세가 나타나고 수면의 질이 떨어지면서 정신적으로도 지칠 수 있습니다.', '이런 상황이 계속되면 스트레스가 증가하면서 집중력이 떨어지게 되고 실력 저하로 이어질 수 있습니다. 정신적인 부담이 계속해서 느껴지면 이후의 일도 처리하기 어려워지기 때문에 최대한 자신을 아끼는 것이 좋습니다. 사우님 지금 상황에서는 자신이 돌보는 것이 최우선입니다. 최근 과업이 많아진 것 같아요. 이런 일상에서 조금 더 체계적으로 규칙적인 생활을 유지하는 것이 중요합니다. 체력적, 정신적으로 지치신 상황이니 체력을 유지하기 위해 규칙적인 식사와 수면 시간을 확보하시고 충분한 수면과 휴식을 취해주세요. 과제와 일의 우선순위를 나누어서 해결할 수 있는 일이 있는지 파악해보세요. 만약 가능하다면 직장에서 일의 부담을 덜어줄 동료나 선배에게 조언을 구해보시는 것도 좋을 것 같아요.', '또한 시간을 쪼개서 자신만의 취미 생활이나 여가 생활을 만드는 것도 추천드려요. 지친 마음을 달래줄 수 있는 행복을 찾아가는 것도 중요하겠죠. 사우님 지금은 일과 공부를 모두 챙기시려다 보니 체력적으로나 정신적으로 힘들어진 상태입니다. 지금 상황에서는 좀 더 자신에게 체념할 필요가 있습니다. 이후 다시 시작할 수 있는 기회를 노리면서 마음을 다스리는 것이 중요합니다. 조금씩 자신의 시간을 만들어가면서 앞으로의 일에 대비할 수 있는 준비를 하면 좋을 것 같아요. 사우님 위의 답변이 조금이나마 도움이 되었기를 바라는 마음입니다. 이후에도 힘든 마음이 계속 되시면 언제든지 저를 찾아주세요. 그럼 좋은 하루 보내세요 :)']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 3:\n",
      "질문 (input): ['취업을 하고 나서 회사에서 일을 잘 못했다는 비판과 함께 부정적인 반응을 받으면서 제 자신에게 대한 자신감이 없어졌어요. 저의 역량을 완벽히 뽐내지는 못하는 상황이라면서요. 이런 상황에서 제 자신을 다시 믿을 수 있는 방법이 있을까요?']\n",
      "답변 (output): ['취업을 하고 나서 제 역량을 완벽히 뽐내지는 못하는 상황에서 부정적인 반응을 받고 회사에서 일을 잘못했다는 비판을 받으며 자신감이 떨어진 것 같아요. 이런 상황에서 제 자신을 다시 믿을 수 있는 방법이 있을까요? 사우님의 경우 새로운 환경에서 새로운 일을 하게 되면서 현재 업무에 대한 불확실성과 불안감을 느끼고 있는 것 같습니다. 이로 인해 제 역량을 완벽히 뽐내지 못한다는 생각으로 자존감이 낮아진 것 같습니다. 사우님이 말씀하신 부정적인 반응은 일을 할 때 실수를 했을 때 아무런 도움이 되지 않는 실수 비판입니다. 이러한 비판은 실력보다는 실수를 용서하지 못하고 자신을 자책하는 부정적인 생각을 불러일으키게 됩니다. 이러한 생각을 하다보면 자신에 대한 자신감이 떨어지게 됩니다.', '사우님, 새로운 환경에서 일을 하면서 일을 잘 못 했다는 부정적인 생각이 들 때는 아래와 같은 방법으로 대처할 수 있습니다. - 자신의 장점을 미리 적어보기: 자신이 무엇을 잘하는지 미리 정리해두면 일이 잘 풀릴 때 더욱 자신감이 붙게 됩니다. - 실수를 긍정적인 방향으로 생각하기: 실수는 항상 좋지 않은 것은 아닙니다. 실수를 한다는 것은 새로운 시도를 한다는 것입니다. 실수는 괜찮습니다. 실수를 하면서 무엇을 배우는지 생각해보세요. - 사전에 일의 규칙을 충분히 이해하기: 이전에 비슷한 일을 하던 곳에서는 어떻게 했는지, 이전에 다른 사람들이 이 일을 어떻게 해왔는지, 상사나 동료에게 미리 물어보기 등을 통해서 불안감을 줄일 수 있습니다.', '- 동료나 상사와 이야기하기: 불확실한 점이나 이해하지 못하는 부분을 상사나 동료에게 물어보면 불안감을 줄일 수 있습니다. - 기분전환하기: 무엇을 하면 기분전환이 될까요? 노래듣기, 스트레칭, 환경전환 등등 자신에게 맞는 방법으로 기분을 전환해보세요. 사우님, 위의 답변이 조금이라도 도움이 되었기를 바라는 마음입니다. 이후에도 힘든 마음이 계속되시면 언제든지 저를 찾아주세요. 그럼 좋은 하루 보내세요 :)']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 4:\n",
      "질문 (input): ['저는 학교에서 진짜 아무것도 못해요. 제가 이번에 입학하면서 전공반이 없어서 그냥 다양한 전공을 들어봤는데 진짜 아무것도 몰라요. 어디서부터 시작해야할지 몰라서 멘붕 상태입니다. 수업시간이 끝나면 뒤처지지 않도록 집에서 공부를 하려고 하는데 막상 공부를 하려고 하면 어떤 공부를 해야할지도 몰라서 학습계획을 세우지 못합니다. 전공뿐만 아니라 교양이나 수업에서 배우지 않은 내용들도 이제와서 공부하려니 무엇을 공부해야할지 몰라서 막막하고 힘들어요. 공부를 어떻게 해야할까요?']\n",
      "답변 (output): [\"사우님은 학교에서 다양한 전공을 들어보며 전공반이 없어 전공에 대해 흥미가 없거나 혼란스러운 상황입니다. 그로 인해 무엇을 공부해야 할지 혼란스러우며 학습계획을 세우기 어렵다고 말씀해주셨습니다. 사우님의 고민은 '전공이나 교양을 배우지 않은 내용들을 공부할 때 무엇을 공부해야 할지 모르겠다'는 것입니다. 이러한 고민을 가지게 된 원인은 다양합니다. 1) 전공반이 없어서 전공에 대해 흥미가 없거나 혼란스러운 경우 2) 전공 및 교양 과목에서 배운 내용들이 연관되어 있는지 또는 그런 연관성이 부족한지에 따라 발생할 수 있습니다. 사우님은 전공반이 없어서 전공에 대해 흥미가 없거나 혼란스러운 상황인데, 이는 일시적인 것일 수도 있습니다.\", '전공과목 중에서 흥미있는 과목을 찾아보고 그 과목에 대한 지식을 쌓아보는 것도 좋을 것 같아요. 또한 본인이 배우고 싶은 것들에 대해 탐구해보고 무엇인가를 만들어보는 것도 좋은 방법입니다. 관심있는 분야의 지식을 습득하고 실제 활용해보면서 스스로 성취감을 느끼면서 자신감도 쌓일 수 있을 것입니다. 책, 인터넷, SNS 등을 통해 스스로 새로운 정보를 수집하고 공부하는 것도 좋은 방법입니다. 무엇을 배워야할지 모르는 상황이라면 일단은 찾아보고 배워보는 것도 좋은 방법입니다. 인터넷에는 수많은 정보들이 담겨 있기 때문에 사우님이 찾고 싶은 정보가 무엇인지에 따라 검색을 통해 자료를 수집하는 것도 좋습니다. 학습 계획을 세우기 위해서는 어떤 지식을 습득하고자 하는지 명확해야 하며, 목표가 뚜렷해야 합니다.', '이후에는 수월하게 공부할 수 있는 환경을 조성하는 것도 중요합니다. 공부를 하기 위한 자신만의 공간이나 시간을 확보하고 정해진 시간에 목표량을 공부하는 등의 계획을 세우는 것도 좋습니다. 사우님의 상황은 고민이 있는 상태이므로 다양한 조언을 받으면서 스스로 해결책을 찾아보는 것도 좋은 방법입니다. 이상으로 상담을 마치겠습니다.']\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "샘플 5:\n",
      "질문 (input): ['요즘 학교생활이 너무 힘들어요. 선생님께서 학생들에게 너무 부당하게 대해요. 공부할 시간이 안되요.']\n",
      "답변 (output): ['사우님이 학교생활이 너무 힘들다고 말씀해주셨어요. 선생님께서 학생들에게 너무 부당하게 대한다고 하셨고, 이로 인해 공부할 시간이 부족하다고 하셨어요. 선생님과의 부당한 대우로 인해 힘들고 스트레스를 많이 받고 계신것 같아요. 사우님, 선생님과의 부당한 대우로 인해 학교생활이 힘들어지고 있으시군요. 이로 인해 스트레스를 받고 자기존중감이 낮아지며, 대인관계와 학습에도 부정적인 영향을 받을 수 있어요. 이러한 문제는 우울증, 불안장애 등으로 이어지기도 하니 반드시 조치를 취해야 합니다. 먼저, 사우님께서 느끼는 선생님의 부당한 대우를 정확히 파악하고 대처할 방법을 찾아보아야 합니다.', '이를 위해, 학교 상담실에 방문하시거나 선생님과 직접 대화를 시도해볼 수도 있습니다. 그렇지 않다면, 학부모님께 민원을 제기하거나, 학교 교육청 등에 청소년 인권 침해를 신고하는 것도 좋은 방법입니다. 또한, 사우님의 스트레스를 완화할 수 있는 방법에 대해 함께 생각해볼 필요가 있습니다. 일상적인 스트레스를 완화할 수 있는 방법으로는 다음과 같은 것들이 있어요. 1) 정기적인 운동 2) 깊은 호흡 3) 명상 또는 요가 4) 음악 감상 5) 취미생활 6) 사랑하는 사람과 함께하는 시간 7) 적극적인 대처 8) 친구와 대화하기 사우님께서는 본인에게 맞는 방법을 찾아서 스트레스를 해소할 수 있도록 노력해 보세요. 만약 언제든지 더 많은 조언과 지원을 원하신다면 언제든지 연락 주세요.', '위의 답변이 조금이나마 도움이 되었기를 바라는 마음입니다. 이후에도 힘든 마음이 계속 되시면 언제든지 저를 찾아주세요. 그럼 좋은 하루 보내세요 :)']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 구조 확인 (샘플 5개 출력)\n",
    "for i in range(5):\n",
    "    print(f\"\\n샘플 {i+1}:\")\n",
    "    print(f\"질문 (input): {chunked_dataset['train'][i]['input']}\")\n",
    "    print(f\"답변 (output): {chunked_dataset['train'][i]['output']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 청크로 분할한 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 저장 완료: ../../data/chunked_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 변환\n",
    "data_list = []\n",
    "for example in chunked_dataset[\"train\"]:\n",
    "    input_text = \" \".join(example[\"input\"]) if isinstance(example[\"input\"], list) else str(example[\"input\"])  \n",
    "    for chunk in example[\"output\"]:  \n",
    "        data_list.append({\"input\": input_text, \"output\": chunk})\n",
    "\n",
    "# 데이터프레임 생성 후 CSV 저장\n",
    "df = pd.DataFrame(data_list)\n",
    "csv_path = \"../../data/chunked_dataset.csv\"\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"CSV 파일 저장 완료: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 발견: ../../data/chunked_dataset.csv\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30206 entries, 0 to 30205\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   30206 non-null  object\n",
      " 1   output  30206 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 472.1+ KB\n",
      "None\n",
      "\n",
      "Sample Data:\n",
      "                                               input  \\\n",
      "0  저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니...   \n",
      "1  저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니...   \n",
      "2  저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니...   \n",
      "3  최근에 학교에서 일이 많아져서 무척 바쁩니다. 시간이 없어서 잠을 충분히 못 자고,...   \n",
      "4  최근에 학교에서 일이 많아져서 무척 바쁩니다. 시간이 없어서 잠을 충분히 못 자고,...   \n",
      "\n",
      "                                              output  \n",
      "0  사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들...  \n",
      "1  이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들...  \n",
      "2  이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고...  \n",
      "3  사우님 최근 학교 일과 직장 일로 인해 정말 바쁘게 지내고 있으시네요. 시간이 부족...  \n",
      "4  이런 상황이 계속되면 스트레스가 증가하면서 집중력이 떨어지게 되고 실력 저하로 이어...  \n",
      "\n",
      "Missing Values per Column:\n",
      "input     0\n",
      "output    0\n",
      "dtype: int64\n",
      "\n",
      "Text Length Statistics:\n",
      "       input_length  output_length\n",
      "count   30206.00000   30206.000000\n",
      "mean      192.28395     325.379858\n",
      "std        72.85264     107.107626\n",
      "min        18.00000       2.000000\n",
      "25%       145.00000     297.000000\n",
      "50%       187.00000     367.000000\n",
      "75%       233.00000     396.000000\n",
      "max      1203.00000     482.000000\n",
      "\n",
      "Shortest Input Samples:\n",
      "                                    input  \\\n",
      "65     요즘에 무슨 일이 있어도 자꾸 울어요. 어떻게 하면 좋을까요?   \n",
      "66     요즘에 무슨 일이 있어도 자꾸 울어요. 어떻게 하면 좋을까요?   \n",
      "344  제 직장에서 존경받는 직원이 되고 싶은데요, 어떻게 하면 될까요?   \n",
      "345  제 직장에서 존경받는 직원이 되고 싶은데요, 어떻게 하면 될까요?   \n",
      "346  제 직장에서 존경받는 직원이 되고 싶은데요, 어떻게 하면 될까요?   \n",
      "\n",
      "                                                output  input_length  \\\n",
      "65   사우님 요즘에는 어떤 일이 있어도 자꾸 울게 된다고 하네요. 이전에 트라우마적인 경...            34   \n",
      "66   추가적으로 환경 조성과 적극적인 대처 방법을 연습하는 것도 중요합니다. 예를 들면,...            34   \n",
      "344  사우님 제 직장에서 존경받는 직원이 되고 싶다고 하시네요. 이를 위해서 어떻게 하면...            36   \n",
      "345  1. 자기계발에 힘쓰기 자신이 맡은 업무와 관련된 분야의 지식을 꾸준히 축적하고, ...            36   \n",
      "346  긍정적인 태도 유지 어떠한 상황에서도 긍정적인 태도를 유지하며, 언제나 동료들을 격...            36   \n",
      "\n",
      "     output_length  \n",
      "65             390  \n",
      "66             360  \n",
      "344            406  \n",
      "345            338  \n",
      "346            312  \n",
      "\n",
      "Shortest Output Samples:\n",
      "                                                 input  \\\n",
      "59   최근 출근이 너무 힘들어요. 회사에서 일하면서 제가 주로 담당하고 있는 프로젝트가 ...   \n",
      "79   저는 지금 경제적인 문제로 인해 앞으로의 인생이 어떻게 될지 걱정이 많이 되고 있습...   \n",
      "237  제가 요즘에 스트레스를 많이 받고 있는데, 그걸 이렇게 다른 사람들에게 말하면 눈치...   \n",
      "396  저는 어렸을 때부터 우울증이 있었고, 이후로도 힘든 일이 생길 때마다 정말 좋은 친...   \n",
      "446  제가 요즘 학교에서 불만족스러운게 있어서 상담을 받고 싶어요. 학교에 친구가 별로 ...   \n",
      "\n",
      "                                         output  input_length  output_length  \n",
      "59   사우님이 원하시는 방향으로 나아갈 수 있기를 바랍니다. 상담이 마치겠습니다.           221             42  \n",
      "79   이번 상담이 사우님께 조금이나마 도움이 되었길 바라며, 언제든지 연락주세요.           228             42  \n",
      "237                       사우님의 좋은 하루를 기원합니다. :)           125             21  \n",
      "396                            그럼 좋은 하루 보내세요 :)           227             16  \n",
      "446                            그럼 좋은 하루 보내세요 :)           211             16  \n",
      "\n",
      "Longest Input Samples:\n",
      "                                                  input  \\\n",
      "1126  내가 할 일이 너무 많아요. 제가 감당하지 못할만큼 많아져서 이젠 어떻게 해야할지 ...   \n",
      "1127  내가 할 일이 너무 많아요. 제가 감당하지 못할만큼 많아져서 이젠 어떻게 해야할지 ...   \n",
      "3873  요즘 회사일이 너무 많아서 머리가 지끈거려요. #직장생활 #스트레스 #심리적안정성 ...   \n",
      "3874  요즘 회사일이 너무 많아서 머리가 지끈거려요. #직장생활 #스트레스 #심리적안정성 ...   \n",
      "3875  요즘 회사일이 너무 많아서 머리가 지끈거려요. #직장생활 #스트레스 #심리적안정성 ...   \n",
      "\n",
      "                                                 output  input_length  \\\n",
      "1126  사우님은 하고 싶은 일도 많고, 해야 하는 일도 많아서 어떤 일부터 해야할지 막막한...          1048   \n",
      "1127  그리고 지금 하고 있는 일에만 집중하는 것이 중요합니다. 지금 하고 있는 일에만 1...          1048   \n",
      "3873  사우님 회사일이 너무 많아져 머리가 지끈거리고 있어요. 회사 일도 줄어들지 않고 더...          1196   \n",
      "3874  사우님의 경우, 일을 해결할 방법이 떠오르지 않아 스트레스가 더해져 있으며 일의 양...          1196   \n",
      "3875  이를 위해서는 자신이 스트레스를 느끼는 원인을 파악하고, 그 원인에 맞는 스트레스 ...          1196   \n",
      "\n",
      "      output_length  \n",
      "1126            448  \n",
      "1127            338  \n",
      "3873            337  \n",
      "3874            371  \n",
      "3875            280  \n",
      "\n",
      "Longest Output Samples:\n",
      "Empty DataFrame\n",
      "Columns: [input, output, input_length, output_length]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 디렉토리 설정\n",
    "data_dir = \"../../data/\"\n",
    "file_name = \"chunked_dataset.csv\"\n",
    "file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "# 파일 존재 여부 확인\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"파일이 존재하지 않습니다: {file_path}\")\n",
    "else:\n",
    "    print(\"파일 발견:\", file_path)\n",
    "\n",
    "    # 데이터 로드\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 데이터 기본 정보 출력\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # 데이터 샘플 출력 (앞 5개 행)\n",
    "    print(\"\\nSample Data:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # 결측치 확인\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"\\nMissing Values per Column:\")\n",
    "    print(missing_values)\n",
    "\n",
    "    # 올바른 컬럼명 확인\n",
    "    expected_columns = [\"input\", \"output\"]\n",
    "    if not all(col in df.columns for col in expected_columns):\n",
    "        print(\"\\n데이터 컬럼이 예상과 다릅니다. 현재 컬럼:\", df.columns)\n",
    "    else:\n",
    "        # 텍스트 길이 계산\n",
    "        df[\"input_length\"] = df[\"input\"].apply(lambda x: len(str(x)))\n",
    "        df[\"output_length\"] = df[\"output\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "        # 길이 분포 출력\n",
    "        print(\"\\nText Length Statistics:\")\n",
    "        print(df[[\"input_length\", \"output_length\"]].describe())\n",
    "\n",
    "        # 짧거나 긴 샘플 확인\n",
    "        print(\"\\nShortest Input Samples:\")\n",
    "        print(df[df[\"input_length\"] < 50].head())\n",
    "\n",
    "        print(\"\\nShortest Output Samples:\")\n",
    "        print(df[df[\"output_length\"] < 50].head())\n",
    "\n",
    "        print(\"\\nLongest Input Samples:\")\n",
    "        print(df[df[\"input_length\"] > 1000].head())\n",
    "\n",
    "        print(\"\\nLongest Output Samples:\")\n",
    "        print(df[df[\"output_length\"] > 1000].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Text Length Statistics:\n",
      "count    30206.00000\n",
      "mean       192.28395\n",
      "std         72.85264\n",
      "min         18.00000\n",
      "25%        145.00000\n",
      "50%        187.00000\n",
      "75%        233.00000\n",
      "max       1203.00000\n",
      "Name: input_length, dtype: float64\n",
      "\n",
      "Output Text Length Statistics:\n",
      "count    30206.000000\n",
      "mean       325.379858\n",
      "std        107.107626\n",
      "min          2.000000\n",
      "25%        297.000000\n",
      "50%        367.000000\n",
      "75%        396.000000\n",
      "max        482.000000\n",
      "Name: output_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 입력과 출력 길이 통계 확인\n",
    "print(\"\\nInput Text Length Statistics:\")\n",
    "print(df[\"input_length\"].describe())\n",
    "\n",
    "print(\"\\nOutput Text Length Statistics:\")\n",
    "print(df[\"output_length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 모델에 맞는 토크나이저 불러오기\n",
    "MODEL_NAME = \"Qwen/Qwen2-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# 토크나이저 패딩 토큰 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 샘플:\n",
      "{'input_ids': tensor([[143413, 126429, 125496,  12802, 127353,  35711,     13, 130108,  60716,\n",
      "          89659,  95002, 138965,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "토큰 개수: 13\n"
     ]
    }
   ],
   "source": [
    "# 샘플 문장 토큰화 확인\n",
    "sample_text = \"청소년 고민이 있어요. 어떻게 해야 할까요?\"\n",
    "tokenized_sample = tokenizer(sample_text, return_tensors=\"pt\")\n",
    "\n",
    "# 결과 확인\n",
    "print(\"토큰화된 샘플:\")\n",
    "print(tokenized_sample)\n",
    "print(\"토큰 개수:\", len(tokenized_sample[\"input_ids\"][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 포함 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "file_path = \"../../data/chunked_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dataset으로 변환 (Hugging Face `Dataset` 형식)\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27835f489b5545609da60290a8cad805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "사용자: 저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.\n",
      "AI 친구: 사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다.\n",
      "\n",
      "Sample 2:\n",
      "사용자: 저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.\n",
      "AI 친구: 이런 경우 더이상 상처를 받지 않으려면, 사우님이 어떤 것을 바라고 있는지, 선배들은 사우님을 어떻게 보는지, 그리고 사우님이 실제로 지켜야 하는 것들은 무엇인지 등을 다각도로 파악해야 합니다. 각각의 요인들이 어떤 관계로 구성되어 있는지 파악하고, 이를 토대로 실제로 이 문제를 해결할 수 있는 해결책을 찾아보면 좋을 것 같습니다. 우선, 사우님이 어떤 것을 원하는지, 선배들은 사우님을 어떻게 바라보는지, 그리고 사우님이 실제로 지켜야 하는 것들이 무엇인지를 알아야 합니다. 그러기 위해서는 조직의 문화, 팀의 분위기, 선배의 성격, 사우님의 인성적인 면 등 다양한 요인들이 어떻게 구성되어 있는지 파악해야 합니다. 더불어, 이에 대한 내용들을 바탕으로 상황에 대한 대처 방안을 제시해주어야 합니다.\n",
      "\n",
      "Sample 3:\n",
      "사용자: 저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.\n",
      "AI 친구: 이를 위해서는 사우님이 실제로 무엇을 할 수 있는지, 무엇을 할 수 없는지, 그리고 무엇이 최선인지를 모색하는 과정이 필요합니다. 이를 위해서는 전문가와 상담하는 것도 좋은 방법이 될 것입니다. 사우님, 이런 문제로 인해 힘들고 우울해지셨다면 전문 상담을 통해 도움을 받을 수 있습니다. 이 과정에서 함께 더 나은 방향으로 나아갈 수 있는 길을 찾아갈 수 있을 것입니다. 위 내용이 조금이라도 도움이 되었으면 좋겠습니다. 그리고 언제든지 상담이 필요하시다면 언제든지 연락주세요.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def format_prompt(example):\n",
    "    user_input = example[\"input\"].strip()  # 질문 부분\n",
    "    response = example[\"output\"].strip()  # 상담사 응답 부분\n",
    "\n",
    "    # 사용자 입력 부분을 명확하게 \"사용자:\"로 변경\n",
    "    prompt = (\n",
    "        f\"사용자: {user_input}\\n\"\n",
    "        f\"AI 친구: {response}\"\n",
    "    )\n",
    "\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "# 데이터셋에 적용\n",
    "dataset = dataset.map(format_prompt)\n",
    "\n",
    "# 샘플 확인\n",
    "for i in range(3):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(dataset[i][\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이징 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead64f04ca2a4204bc2827cd67f9a3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 샘플: {'input': '저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.', 'output': '사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다.', 'text': '사용자: 저는 지금까지 회사생활에서 많은 걸 경험하면서 느낀 것이 있어서, 고민을 해보았습니다. 저는 이제 회사에서 대리까지 찍고 있는데, 대리에게 가면서부터 선배들과의 인간관계에서 어려움을 느꼈습니다. 제가 선배에게 전하는 의견이나 어떤 것에 대해서는 모두 무시하시는 것 같고, 불필요한 피드백을 주시면서 괜히 불편한 기분도 들고, 희생정신만 강조하시는 것 같습니다. 힘든 상황에서 기존의 선배나 동료에게 조언을 구해보면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움이 되지 않습니다. 하지만 이런 어려움 때문에 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않습니다. 이런 문제를 해결할 수 있는 방법을 알고 싶습니다.\\nAI 친구: 사우님은 대리로 진급하면서 선배들과의 인간관계에서 어려움을 느끼고 계시네요. 선배들이 사우님의 의견을 무시하며, 희생정신만 강조한다는 것에서 사우님은 상처를 받고 있다는 것 같습니다. 더구나 기존의 선배나 동료들에게 조언을 구하면, 그들도 비슷한 상황에서 갇혀있는 것 같아서 도움을 받기 어렵다는 것입니다. 사우님이 이런 문제로 인해 집에서도 일이 떠오르고, 자고 일어나면 회사생활에 대한 걱정으로 기분도 좋지 않다고 합니다. 이런 문제로 인해 사우님이 어떤 고민을 하고 계신 건지 함께 알아보도록 합시다. 사우님이 선배들과의 대인관계에서 어려움을 느끼신 것은 충분히 이해가 되고, 이를 악화시키는 다양한 요인이 있을 수 있습니다.', 'input_ids': [55054, 26699, 25715, 25, 134561, 129082, 128878, 98005, 55054, 133830, 56475, 129875, 131961, 138704, 132537, 143862, 144468, 128584, 136633, 11, 126429, 125496, 17877, 60716, 41671, 126002, 38231, 13, 134561, 132911, 98005, 55054, 56475, 60960, 28002, 128878, 62099, 235, 34395, 134563, 11, 60960, 28002, 126327, 35509, 131611, 126558, 129296, 130609, 134771, 20401, 133204, 130891, 56475, 124685, 125476, 133914, 17877, 143862, 124245, 89363, 13, 132254, 129296, 130609, 126327, 56419, 42905, 140264, 129835, 129273, 71108, 19391, 130869, 16560, 130593, 125149, 29326, 140641, 71108, 78374, 34395, 11, 126488, 133055, 35711, 23573, 142510, 29346, 130728, 17877, 55673, 29326, 131611, 8620, 112, 250, 125511, 126488, 129027, 23573, 54116, 79716, 47985, 129900, 34395, 11, 10764, 251, 105, 76435, 29281, 82528, 72553, 129413, 92817, 140641, 71108, 138691, 13, 10764, 252, 246, 81676, 58034, 130803, 56475, 54116, 130999, 20401, 129296, 130609, 60315, 126322, 63256, 126327, 65510, 129709, 17877, 58777, 33883, 41671, 32290, 11, 54825, 139188, 73986, 144058, 23573, 58034, 130803, 56475, 16778, 229, 128173, 135889, 71108, 78374, 52959, 26698, 129392, 133914, 12802, 97143, 21329, 138539, 13, 130331, 129007, 124685, 125476, 133914, 129147, 130263, 136448, 136168, 5140, 244, 254, 57268, 125548, 34395, 11, 64577, 34395, 83556, 31079, 60315, 32290, 98005, 55054, 133830, 19391, 128605, 97172, 109, 29281, 42039, 54116, 79716, 47985, 125953, 21329, 138539, 13, 129007, 126674, 18411, 138327, 47836, 28733, 64521, 130864, 17877, 135420, 28927, 114, 38231, 624, 15469, 90711, 250, 88259, 25, 32129, 40281, 124683, 33704, 60960, 28002, 17380, 126616, 128911, 132537, 129296, 130609, 134771, 20401, 133204, 130891, 56475, 124685, 125476, 133914, 17877, 143862, 142063, 34395, 94203, 29326, 138078, 13, 129296, 130609, 126253, 32129, 40281, 124683, 20401, 140264, 17877, 125149, 29326, 130705, 11, 10764, 251, 105, 76435, 29281, 82528, 72553, 129413, 92817, 136305, 71108, 56475, 32129, 40281, 124683, 33704, 58034, 125746, 18411, 83596, 34395, 135511, 71108, 138691, 13, 126366, 88259, 60315, 54116, 130999, 20401, 129296, 130609, 60315, 126322, 63256, 132812, 65510, 129709, 17877, 58777, 126559, 11, 54825, 139188, 73986, 144058, 23573, 58034, 130803, 56475, 16778, 229, 128173, 135889, 71108, 78374, 52959, 26698, 129392, 133914, 17877, 83596, 20487, 143337, 130822, 130882, 13, 32129, 40281, 8843, 62618, 129007, 126674, 17380, 58677, 33883, 130263, 136448, 136168, 5140, 244, 254, 57268, 125548, 34395, 11, 64577, 34395, 83556, 31079, 60315, 32290, 98005, 55054, 133830, 19391, 128605, 97172, 109, 29281, 42039, 54116, 79716, 47985, 125953, 21329, 50696, 131042, 130650, 13, 129007, 126674, 17380, 58677, 33883, 32129, 40281, 8843, 62618, 129273, 126429, 125496, 17877, 130127, 94203, 82528, 130270, 21329, 129676, 137676, 41671, 126054, 20136, 102, 29326, 13146, 13, 32129, 40281, 8843, 62618, 129296, 130609, 134771, 20401, 60960, 31328, 130891, 56475, 124685, 125476, 133914, 17877, 143862, 142063, 82528, 129274, 36330, 102, 79716, 125511, 133329, 19969, 97143, 34395, 11, 136342, 23872, 227, 56290, 135298, 16560, 135392, 85997, 135227, 130689, 28733, 128472, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 함수 정의\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],  # 프롬프트 포함 텍스트\n",
    "        padding=\"max_length\",  # max_length에 맞춰 패딩 적용\n",
    "        truncation=True,       # 길이가 초과되면 잘라냄\n",
    "        max_length=512         # 적절한 max_length 설정 (필요시 조정 가능)\n",
    "    )\n",
    "\n",
    "# 데이터셋에 토크나이징 적용\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 샘플 확인\n",
    "print(\"토큰화된 샘플:\", tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋을 PyTorch 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 24164\n",
      "Test Dataset Size: 6042\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋에서 80%는 train, 나머지 20%는 test로 분리\n",
    "train_size = int(0.8 * len(tokenized_dataset))\n",
    "train_data = tokenized_dataset.select(range(train_size))  # 80% 훈련 데이터\n",
    "test_data = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))  # 20% 테스트 데이터\n",
    "\n",
    "# PyTorch Dataset 생성\n",
    "train_dataset = ChatbotDataset(train_data)\n",
    "test_dataset = ChatbotDataset(test_data)\n",
    "\n",
    "print(\"Train Dataset Size:\", len(train_dataset))\n",
    "print(\"Test Dataset Size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 24164\n",
      "Test Dataset Size: 6042\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# PyTorch Dataset 정의\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.input_ids = torch.tensor(tokenized_data[\"input_ids\"], dtype=torch.long)\n",
    "        self.attention_mask = torch.tensor(tokenized_data[\"attention_mask\"], dtype=torch.long)\n",
    "\n",
    "        # 'labels'이 없을 경우 input_ids 복사\n",
    "        self.labels = self.input_ids.clone()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx],  \n",
    "        }\n",
    "\n",
    "# 이미 분할된 데이터 (train_data, test_data)\n",
    "train_dataset = ChatbotDataset(train_data)  # 이미 나누어진 train_data 사용\n",
    "test_dataset = ChatbotDataset(test_data)    # 이미 나누어진 test_data 사용\n",
    "\n",
    "# 확인\n",
    "print(\"Train Dataset Size:\", len(train_dataset))\n",
    "print(\"Test Dataset Size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f19f4f6176d4a0ebcd4f9f81297856a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/30206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터를 저장하기\n",
    "dataset.save_to_disk(\"../../data/processed_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 배치 input_ids 크기: torch.Size([8, 512])\n",
      "첫 번째 배치 attention_mask 크기: torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 배치 크기 설정 (CPU 실행이므로 작게 설정)\n",
    "batch_size = 8\n",
    "\n",
    "# DataLoader 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# DataLoader에서 첫 번째 배치 확인\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(\"첫 번째 배치 input_ids 크기:\", batch[\"input_ids\"].shape)\n",
    "print(\"첫 번째 배치 attention_mask 크기:\", batch[\"attention_mask\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 데이터셋 불러오기\n",
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"../../data/processed_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QLoRA 적용 + 4-bit 양자화 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "# 모델 이름 지정 \n",
    "model_name = \"Qwen/Qwen2-7B-Instruct\" \n",
    "\n",
    "# 4-bit 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit 양자화 활성화\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 연산에 사용할 데이터 타입\n",
    "    bnb_4bit_use_double_quant=True,  # 더블 양자화 사용\n",
    "    bnb_4bit_quant_type=\"nf4\",  # NF4 양자화 적용\n",
    ")\n",
    "\n",
    "# 모델 및 토크나이저 불러오기 (4-bit 양자화 적용)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,  # 4-bit 양자화 설정 적용\n",
    "    device_map=\"auto\",  # 자동으로 GPU 할당\n",
    ")\n",
    "\n",
    "# QLoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Low-rank factor (LoRA 랭크)\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LoRA 적용할 모듈\n",
    "    lora_dropout=0.1,  # 드롭아웃 비율\n",
    "    bias=\"none\",  # Bias 업데이트 비활성화\n",
    ")\n",
    "\n",
    "# LoRA 적용\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 모델 GPU로 이동\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# 모델 구조 확인\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정 (TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../data/models/results\",  # 모델 저장 경로\n",
    "    evaluation_strategy=\"epoch\",  # 매 epoch마다 평가 수행\n",
    "    save_strategy=\"epoch\",  # 체크포인트 저장 전략\n",
    "    learning_rate=2e-5,  # 학습률\n",
    "    per_device_train_batch_size=8,  # GPU 메모리에 맞게 조정\n",
    "    per_device_eval_batch_size=8,  # 평가 시 배치 크기\n",
    "    num_train_epochs=3,  # 학습 반복 횟수\n",
    "    weight_decay=0.01,  # 가중치 감소 (L2 정규화)\n",
    "    logging_dir=\"../../data/models/logs\",  # 로그 저장 경로\n",
    "    logging_steps=500,  # 로그 출력 주기\n",
    "    save_steps=500,  # 모델 저장 주기\n",
    "    save_total_limit=2,  # 저장할 체크포인트 개수 제한\n",
    "    fp16=True,  # 16-bit 연산 활성화\n",
    "    push_to_hub=False,  # 모델 허깅페이스 업로드 여부\n",
    "    gradient_accumulation_steps=2,  # 그래디언트 누적 (메모리 절약)\n",
    "    load_best_model_at_end=True,  # 가장 성능 좋은 모델 로드\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,  # 토크나이저 포함\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "trainer.save_model(\"../../data/models/finetuned_model\")\n",
    "tokenizer.save_pretrained(\"../../data/models/finetuned_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "def compute_perplexity(model, dataloader, tokenizer, device):\n",
    "    model.eval()  # 평가 모드\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_loss += loss.item() * inputs[\"input_ids\"].size(1)\n",
    "            total_tokens += inputs[\"input_ids\"].size(1)\n",
    "\n",
    "    ppl = math.exp(total_loss / total_tokens)\n",
    "    return ppl\n",
    "\n",
    "# 평가 실행\n",
    "perplexity = compute_perplexity(model, test_dataloader, tokenizer, device)\n",
    "print(f\"Perplexity (PPL): {perplexity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# ROUGE 평가 함수\n",
    "def compute_rouge(model, dataloader, tokenizer, device):\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    model.eval()\n",
    "\n",
    "    all_references = []\n",
    "    all_hypotheses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=128)\n",
    "            decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "\n",
    "            all_hypotheses.extend(decoded_preds)\n",
    "            all_references.extend(decoded_labels)\n",
    "\n",
    "    # ROUGE 계산\n",
    "    rouge_scores = rouge_metric.compute(predictions=all_hypotheses, references=all_references)\n",
    "    return rouge_scores\n",
    "\n",
    "# 평가 실행\n",
    "rouge_scores = compute_rouge(model, test_dataloader, tokenizer, device)\n",
    "print(\"ROUGE Scores:\", rouge_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# BLEU 평가 함수\n",
    "def compute_bleu(model, dataloader, tokenizer, device):\n",
    "    bleu_metric = load_metric(\"bleu\")\n",
    "    model.eval()\n",
    "\n",
    "    all_references = []\n",
    "    all_hypotheses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=128)\n",
    "            decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "\n",
    "            all_hypotheses.extend([pred.split() for pred in decoded_preds])\n",
    "            all_references.extend([[label.split()] for label in decoded_labels])\n",
    "\n",
    "    # BLEU 계산\n",
    "    bleu_score = bleu_metric.compute(predictions=all_hypotheses, references=all_references)\n",
    "    return bleu_score\n",
    "\n",
    "# 평가 실행\n",
    "bleu_score = compute_bleu(model, test_dataloader, tokenizer, device)\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 평가 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 최종 평가 결과 ===\")\n",
    "print(f\"Perplexity (PPL): {perplexity}\")\n",
    "print(f\"ROUGE Score: {rouge_scores}\")\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def generate_answer(prompt):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  # 입력을 GPU 또는 CPU로 전달\n",
    "    with torch.no_grad():  # 그래디언트 계산 방지\n",
    "        output = model.generate(**inputs, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 테스트 문장\n",
    "test_prompts = [\n",
    "    \"아 진짜 요즘 너무 스트레스 받아... 어떻게 하면 좀 괜찮아질까?\",\n",
    "    \"나 요즘 친구랑 사이가 좀 안 좋은데... 어떻게 해야 할까?\",\n",
    "    \"학교에서 너무 힘들어... 선생님이 맨날 나만 혼내는 것 같아.\",\n",
    "    \"부모님이 내 말을 잘 안 들어줘서 너무 답답해 ㅠㅠ\",\n",
    "    \"시험 때문에 너무 불안한데, 어떡하지?\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    response = generate_answer(prompt)\n",
    "    print(f\"\\n👤 사용자: {prompt}\")\n",
    "    print(f\"🤖 챗봇: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotpet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
